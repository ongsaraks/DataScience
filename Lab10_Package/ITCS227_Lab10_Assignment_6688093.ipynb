{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ba598b-8ece-47dc-bb28-4709b35bdcc7",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://www.ict.mahidol.ac.th/en/\" target=\"_blank\">\n",
    "    <img src=\"https://www3.ict.mahidol.ac.th/ICTSurveysV2/Content/image/MUICT2.png\" width=\"400\" alt=\"Faculty of ICT\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "# Lab10: Introduction to Time Series Modeling - Assignment\n",
    "\n",
    "Time Series modeling is an supervised learning technique for forecasting (generating a future outcome) by using historical data. We will use these techniques for:\n",
    "- `Part 1 - Univariate Forecasting Modeling (\"Local Modeling\")` of a single time series.\n",
    "- `Part 2 - Global Forecasting Modeling` of independent multi-series forecasting.\n",
    "\n",
    "The main focus for this Lab Assignment is on:\n",
    "- Getting to know `Statistical approaches` to time series modeling (which often work best on `small datasets`).\n",
    "- Getting to know `neural network approaches` to forecasting (where `large datasets` are required for good results).\n",
    "- Read through the `Tutorial Notebook` before starting these exercises and questions.\n",
    "\n",
    "\n",
    "__Instructions:__\n",
    "1. Append your ID at the end of this jupyter file name. For example, ```ITCS227_Lab0X_Assignment_6788123.ipynb```\n",
    "2. Complete each task and question in the lab.\n",
    "3. Once finished, raise your hand to call a TA.\n",
    "4. The TA will check your work and give you an appropriate score.\n",
    "5. Submit your IPYNB source code to MyCourses as record-keeping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b99a3-72df-4c00-9839-bf6e081630ca",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "## Prerequisite Check Existing Installation: (takes 20 minutes!)\n",
    "- For this work, we will use the `Darts` time series forecasting library that depends on `PyTorch` (a large [~2.5GB] and very useful modeling library for DNN/CNN). First we check if it's already installed, and then perform the *basic-CPU* install.\n",
    "```python\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "```\n",
    "\n",
    "- `If this fails`:   (takes 20 minutes!)\n",
    "    ```\n",
    "    !pip install torch torchvision torchaudio darts\n",
    "    ```\n",
    "- `If it succeeded`, then you already have PyTorch installed, therefore install Darts:  (takes ~2 minutes!)\n",
    "    ```\n",
    "    !pip install darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab802f-b556-44c9-ad22-be184dbe289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch timport torch\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32f872-2305-4f40-86d9-ad6653644d3a",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "## Load Imports and Library of Helper Functions\n",
    "\n",
    "- Run this cell to use its functions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435bc344-c379-4c81-a76f-d117e4c2cc4c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import ExponentialSmoothing\n",
    "from darts.utils.utils import ModelMode\n",
    "\n",
    "from darts.dataprocessing.transformers import (\n",
    "    Scaler,\n",
    "    MissingValuesFiller,\n",
    "    Mapper,\n",
    "    InvertibleMapper,\n",
    ")\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.metrics import (\n",
    "    coefficient_of_variation,\n",
    "    mae,\n",
    "    mape,\n",
    "    #marre,\n",
    "    mase,\n",
    "    mse,\n",
    "    rmse,\n",
    "    ope,\n",
    "    r2_score\n",
    ")\n",
    "from darts.utils.statistics import check_seasonality, plot_acf, plot_residuals_analysis\n",
    "from darts.utils.timeseries_generation import linear_timeseries\n",
    "\n",
    "from darts.metrics import mape, mae, r2_score, mase\n",
    "\n",
    "\n",
    "def _display_prediction_evaluations(series, train, val, prediction, sharexy=True):\n",
    "    # Calculate metrics for component in a multi-series dataset:\n",
    "    results = {}\n",
    "    for component in series.components:\n",
    "        actual = val[component]\n",
    "        predicted = prediction[component]\n",
    "        insample = train[component]\n",
    "        results[component] = {\n",
    "            \"MASE\": mase(actual, predicted, insample),\n",
    "            \"MAPE\": mape(actual, predicted),\n",
    "            \"MAE\": mae(actual, predicted),\n",
    "            \"R2\": r2_score(actual, predicted)\n",
    "        }\n",
    "    \n",
    "    # Print the results in a table\n",
    "    df_results = pd.DataFrame(results).T  # Transpose for better readability\n",
    "    df_results = df_results.T.rename(columns={i:j for i,j in zip(series.components, columns)}).T\n",
    "    display(df_results)\n",
    "    \n",
    "    # Visualize the results (optional)\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(12, 8), sharex=sharexy, sharey=sharexy)\n",
    "    axes = axes.ravel()\n",
    "    for i, component in enumerate(series.components):\n",
    "        ax = axes[i]\n",
    "        train[component].plot(label=\"Train\", color=\"blue\", ax=ax)\n",
    "        val[component].plot(label=\"Validation\", color=\"green\", ax=ax)\n",
    "        prediction[component].plot(label=\"Prediction\", color=\"red\", ax=ax)\n",
    "        ax.set_title(f'{columns[i]} [{component}]')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb1109-9433-4b45-9278-80f509d8f575",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# \n",
    "# Part 1 - Univariate Forecasting Modeling (\"Local Modeling\") of a single time series. Using Python DARTS Library\n",
    "## Task 1: Forecasting Cow Milk Production with Feature Engineering with Train/Test Split Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895d1f3-3381-4749-b50b-4c51c7e38fe4",
   "metadata": {},
   "source": [
    "### Dataset Load & Prepare:\n",
    "- Average monthly milk production per cow over 14 years (January 1962 - December 1975).\n",
    "- References:\n",
    "    - Makridakis, Wheelwright and Hyndman (1998) Forecasting: methods and applications, John Wiley & Sons: New York. Chapter 2.\n",
    "    - Cryer (1986) Time series analysis, Duxbury Press: Belmont.\n",
    "    - Docs: https://unit8co.github.io/darts/generated_api/darts.datasets.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9f6a3-9e7d-4e86-8cb7-f1e54fd1c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_milk(series, forecast, validation, target_column_name):\n",
    "    known_forecast, uncertain_forecast = forecast[:len(validation)], forecast[len(validation):]\n",
    "    series.plot(label=\"actual\", lw=1)\n",
    "    known_forecast.plot(label=\"measured forecast\", color='blue', lw=1)\n",
    "    if len(uncertain_forecast)>0:\n",
    "        mape_score = mape(known_forecast, validation)\n",
    "        uncertain_forecast.plot(label=\"uncertain forecast\", color='red', ls='dashed', lw=0.25)\n",
    "        d_values = uncertain_forecast.to_dataframe()[target_column_name]\n",
    "        plt.fill_between(uncertain_forecast.to_dataframe().index, \n",
    "                 d_values * (1+(mape_score/100)), \n",
    "                 d_values * (1-(mape_score/100)), \n",
    "                 color='red', alpha=0.15)\n",
    "    plt.legend()\n",
    "    plt.gca().set_ylabel(target_column_name)\n",
    "    plt.title(\"MAPE = {:.2f}%\".format(mape(known_forecast, validation)))\n",
    "    metrics = [coefficient_of_variation,\n",
    "                mae,\n",
    "                mape,\n",
    "                #marre,\n",
    "                #mase,\n",
    "                mse,\n",
    "                rmse,\n",
    "                ope,\n",
    "                r2_score]\n",
    "    print(f\"Known Forecast Period errors (via validation; n={len(validation)}):\")\n",
    "    _ = [print(f'{m.__name__} = {m(known_forecast, validation)}') for m in metrics]\n",
    "    \n",
    "def _plot_box_error(series, prediction_timestamp, pred_value, e_upper, e_lower):\n",
    "    target_column_name = series.to_dataframe().columns[0]\n",
    "    dft = series.to_dataframe()\n",
    "    dft['Year'] = series.to_dataframe().index.year\n",
    "    ax = dft.boxplot(by='Year')\n",
    "    ax.set_ylabel(target_column_name)\n",
    "    years_diff = pd.Timestamp(prediction_timestamp).year - dft.Year.max() \n",
    "    yerr = [[abs(pred_value.iloc[0]-e_upper.iloc[0])], [abs(pred_value.iloc[0]-e_lower.iloc[0])]]\n",
    "    plt.errorbar(len(dft.Year.unique())+years_diff, pred_value, yerr=yerr, fmt='x', color='blue', \n",
    "                 ecolor='red', elinewidth=2, capsize=5, capthick=2, label=f'Predicted value\\nat {pred_value.iloc[0]:.1f} [{e_upper.iloc[0]:.1f}-{e_lower.iloc[0]:.1f}]\\nfor {prediction_timestamp}')\n",
    "    plt.gca().tick_params(axis='x', rotation=45)\n",
    "    xticklabels = plt.gca().get_xticklabels() + [plt.Text(i, 0, f'{j}') for i,j in zip(range(len(dft.Year.unique())+1,len(dft.Year.unique())+years_diff+1), \n",
    "                                                                                     range(dft.Year.max()+1, pd.Timestamp(prediction_timestamp).year+1))]\n",
    "    xticks = [t.get_position()[0] for t in xticklabels]\n",
    "    plt.gca().set_xticks(xticks)\n",
    "    plt.gca().set_xticklabels(xticklabels)\n",
    "    _ = plt.legend()\n",
    "    \n",
    "def _plot_milk_with_prediction(series, new_forecast, validation, pred_value, prediction_timestamp, target_column_name):\n",
    "    _plot_milk(series, new_forecast, validation, target_column_name)\n",
    "    plt.gca().axhline(pred_value.iloc[0], color='g', ls=(0, (5, 10)), lw=0.5)\n",
    "    plt.gca().axvline(pd.Timestamp(prediction_timestamp), color='g', ls=(0, (5, 10)), lw=0.5)\n",
    "    plt.scatter(pd.Timestamp(prediction_timestamp), pred_value, s=15, marker='x', color='g', label=f'Predicted value at {prediction_timestamp}\\n{pred_value.iloc[0]:.3f}')\n",
    "    _ = plt.legend()\n",
    "    \n",
    "def _collect_filled_dataset(get_dataset):\n",
    "    series = get_dataset().load()\n",
    "    filler = MissingValuesFiller()\n",
    "    series = filler.transform(series, method=\"quadratic\")\n",
    "    return series\n",
    "\n",
    "def _get_scale_transformer():\n",
    "    return Scaler(MinMaxScaler(feature_range=(0, 1))) \n",
    "\n",
    "def _collect_scaled_dataset(series):\n",
    "    transformer = _get_scale_transformer()\n",
    "    original_series = series.copy()\n",
    "    series = transformer.fit_transform(series)\n",
    "    return series, transformer\n",
    "\n",
    "def collect_preprocessed_dataset(get_dataset):\n",
    "    series = _collect_filled_dataset(get_dataset)\n",
    "    series, transformer = _collect_scaled_dataset(series)\n",
    "    return series, transformer \n",
    "\n",
    "def model_fit_predict_rmse( model,  training, validation, transformer, predict_period=36, target_column_name='target' ):\n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    \n",
    "    context = SuppressOutput if isinstance(model, LightGBMModel) else NoSpecialAction\n",
    "    with context():\n",
    "        model.fit(training)\n",
    "        forecast = model.predict( predict_period )\n",
    "    \n",
    "    series_ori = transformer.inverse_transform(series.copy())\n",
    "    validation_ori = transformer.inverse_transform(validation.copy())\n",
    "    forecast_ori = transformer.inverse_transform(forecast.copy())\n",
    "    \n",
    "    rmse_score = rmse(forecast_ori, validation_ori)\n",
    "    # _display_rmse(rmse_score)\n",
    "    # _plot_milk(series_ori, new_forecast_ori, validation_ori, target_column_name)\n",
    "    return [{\n",
    "        'model':model.__class__.__name__,\n",
    "        'rmse':rmse_score\n",
    "           }]\n",
    "\n",
    "import sys\n",
    "\n",
    "class NullWriter:\n",
    "    def write(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def flush(self):\n",
    "        pass\n",
    "\n",
    "class NoSpecialAction:\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        pass\n",
    "        \n",
    "class SuppressOutput:\n",
    "    def __enter__(self):\n",
    "        self.original_stdout = sys.stdout  # Save the original stdout\n",
    "        sys.stdout = NullWriter()           # Redirect stdout to NullWriter\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout = self.original_stdout   # Restore original stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0265cbd2-3c1a-4209-882f-fa034044885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from darts.datasets import AirPassengersDataset, MonthlyMilkIncompleteDataset\n",
    "\n",
    "get_dataset = MonthlyMilkIncompleteDataset\n",
    "series = get_dataset().load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d6d89f-6955-4a8f-a7c8-3c1709c5c185",
   "metadata": {},
   "source": [
    "- We're loading a `Time Series dataset`, which is an extension to Pandas DataFrames; however the time \"component\" (is the index and) is external to the historical data. Both are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523bfb2b-d6ce-4936-b611-c41860b2fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(series.to_dataframe() )\n",
    "series.to_dataframe().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6581726-ed87-4223-bb5a-7f82f8b02fd9",
   "metadata": {},
   "source": [
    "- Plot the series data, and notice there are several missing data periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359e690-c7ba-463f-974b-d4d36d6e273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a8334-0242-42be-b4f3-db85ba37b77d",
   "metadata": {},
   "source": [
    "##### Fill in missing values:\n",
    "- Uses quadratic interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda45fbf-c51e-4594-88a3-adcd154ab8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filler = MissingValuesFiller()\n",
    "series = filler.transform(series, method=\"quadratic\")\n",
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b0f34e-8cc1-40c6-83d1-e04ec3b2f82f",
   "metadata": {},
   "source": [
    "##### Normalize the Value Scale\n",
    "\n",
    "**Note:**\n",
    "- (-1,1) or StandardizedScaling (mean==0) are standard recommendations for neural network-based and numerical models, which allow both +/- values in a single unit-variance magnitude.\n",
    "- While (0,1) only controls for magnitudinal range differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397afe4-bb2d-46f4-b6dd-0475a213bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "transformer = Scaler(MinMaxScaler(feature_range=(0, 1))) \n",
    "original_series = series.copy()\n",
    "series = transformer.fit_transform(series)\n",
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed562f64-c3f1-45dc-876c-6a7b4ec94cb3",
   "metadata": {},
   "source": [
    "##### Inverse the normalized scale:\n",
    "- To get our prediction results back the original scale, we must revert the scale; back to the original range.\n",
    "- We can use `inverse_transform()` for this later; and `predictions_ori = transformer.inverse_transform(predictions)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ad1e2-6c2a-447b-aa9f-cfa0d3d7beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 = transformer.inverse_transform(series.copy())\n",
    "series2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915291dd-c440-4916-abc8-76c8c2c344a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transformer.__dict__['_fitted_params'][0]\n",
    "t.scale_, t.min_, t.data_min_, t.data_max_, t.data_min_*t.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57244a6c-34ed-4ff1-bb70-bfaafdd3000f",
   "metadata": {},
   "source": [
    "##### Perform Model Training and Forecast Prediction Error (MAPE) for future milk production:\n",
    "- The `ExponentialSmoothing` algorithm will be used to train the fitted model for prediction. Using a hold-out split of train/validation sets and test sets.\n",
    "- The `MAPE` error will inform us about the mean average percentage error of the model, in terms of % correctness (in the test period).\n",
    "- We will look at `RMSE` error also to discover the predicted milk production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d774d0-0db1-4912-8ef0-83a6faf66a95",
   "metadata": {},
   "source": [
    "### Fit the Exponential Smoothing Model:\n",
    "- Plot the Milk Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e057d-d1e2-45f4-a53f-fe08152d1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = series.to_dataframe().columns[0]\n",
    "training, validation = series.split_before(pd.Timestamp(\"1973-01-01\"))\n",
    "predict_period = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84dfd5-2d44-4b7a-af23-dcb6535beb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import ExponentialSmoothing\n",
    "from darts.utils.utils import ModelMode, SeasonalityMode\n",
    "\n",
    "model = ExponentialSmoothing(\n",
    "    trend=ModelMode.ADDITIVE, \n",
    "    seasonal=SeasonalityMode.ADDITIVE\n",
    ")\n",
    "model.fit(training)\n",
    "forecast = model.predict( predict_period )\n",
    "_plot_milk(series, forecast, validation, target_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a289ccc-9c1e-4d00-b771-ffa6bf90b9c2",
   "metadata": {},
   "source": [
    "##### Interpreting the RMSE error, in terms of the Pounds of Milk per month:\n",
    "- To do this, we have to reverse the earlier data scaling (to return the error value into the correct range).\n",
    "- Essentially, this is $scaling\\_factor * predictions$, then perform the $error = RMSE(y_t,y_p)$ error calculation. Then divide the error over the prediction period (36 months), into a single month's error, per cow in pounds.\n",
    "- We apply `y_pred = transformer.inverse_transform(y_pred)`, then we can re-evaluate `RMSE()` and each of the metrics in the original value range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d7a5f-e59e-45c4-809a-63e20e1844cd",
   "metadata": {},
   "source": [
    "##### Inverse Scaling of Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f1003-edc5-4ec3-8eeb-ef0a2bc07b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ori = transformer.inverse_transform(validation.copy())\n",
    "forecast_ori = transformer.inverse_transform(forecast.copy())\n",
    "series_ori = transformer.inverse_transform(series.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ccf972-a7b4-4477-a0dc-9a79af1d97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _display_rmse(error):\n",
    "    print(f'The model prediction error (RMSE) of Milk Production per cow per month into the forecasted prediction period is:\\n{error:.3f} (pounds per cow per month).')\n",
    "    kgs = error/2.2\n",
    "    print(f'{kgs:.3f} (kilograms per cow per month).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c0dd7-71f8-400d-ac64-6a0eb8c3edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score = rmse(forecast_ori, validation_ori)\n",
    "_display_rmse(rmse_score)\n",
    "\n",
    "rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e13cf-b24d-4413-9ce7-93546a955246",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_milk(series_ori, forecast_ori, validation_ori, target_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa77b5b-75e4-4189-9244-dfb6f17cdb71",
   "metadata": {},
   "source": [
    "##### A Future prediction in an unknown/unseen time period, with expected MAPE error of 4.16%, at 18.380 KG per cow per month.\n",
    "- Let's look at a predicted forecast into the far future. In theory, the model's MAPE error indicates we can expect $\\pm$4.16% error on this forecast estimate.\n",
    "- The dataset ends in 1976, so lets make a forecast for 1980, `4 years` into the \"future\".\n",
    "- We could request  `48=12*4` (monthly) predictions, or request a longer period.\n",
    "- We must be careful in interpreting the error for this `uncertain forecast` period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c51a7-0b2a-48ac-9d03-257590dd7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_forecast = model.predict(n=len(series))\n",
    "new_forecast_ori = transformer.inverse_transform(new_forecast.copy())\n",
    "\n",
    "_plot_milk(series_ori, new_forecast_ori, validation_ori, target_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ac5a2-3bf0-4b86-903b-47f7b4c7e87f",
   "metadata": {},
   "source": [
    "### Make Individual Forecast Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb2a4c-1a22-49e7-a759-b20fe1efc92f",
   "metadata": {},
   "source": [
    "#### Make an \"uncertain\" Forecast Prediction for 1980-09-01 (beyond the dataset):\n",
    "- Collect to the specific-time prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e23172-7506-4bb3-88ce-960420b7560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_timestamp = '1980-09-01'\n",
    "display(new_forecast.to_dataframe().loc[prediction_timestamp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369e3b1-e99d-4810-9471-44407f61f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_value = new_forecast_ori.to_dataframe().loc[prediction_timestamp]\n",
    "pred_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c7767-17a2-48f2-a1aa-f8b18782dd32",
   "metadata": {},
   "source": [
    "##### Plot the prediction value in terms of the forecast, including the MAPE range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485a503-d91f-40ab-87f2-c012616db8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_milk_with_prediction(series_ori, new_forecast_ori, validation_ori, pred_value, prediction_timestamp, target_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7498f1-852c-4c9d-9335-0d9c2ced10c7",
   "metadata": {},
   "source": [
    "#### Add Error Range to Forecast Prediction:\n",
    "- Apply the re-scaling factor, and include the MAPE error range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d9ddc-5822-4c10-b6f0-3d4022bd06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_score = mape(forecast_ori, validation_ori)\n",
    "pred_value, e_upper, e_lower = pred_value, pred_value * (1-(mape_score/100)), pred_value * (1+(mape_score/100))\n",
    "pred_value, e_upper, e_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ab8e3-db1a-4352-81a7-f53fdd3819bb",
   "metadata": {},
   "source": [
    "##### BoxPlot visualization by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00afadf-a066-445b-abd0-b85e7191220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_box_error(series_ori, prediction_timestamp, pred_value, e_upper, e_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a4ae0-7e35-46b2-b254-720fba0f2852",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "## Task 2: Try another model to compare against ExponentialSmoothing Model.\n",
    "- Comparing models is very similar approaches as with Sci-Kit Learn. It is possible to measure `time to fit` and `time to prediction`, as well as `metrics of correctness`, as we have done with `RMSE` and `MAPE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaaf7a2-68af-40cc-8507-1aa4c405afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = series.to_dataframe().columns[0]\n",
    "training, validation = series.split_before(pd.Timestamp(\"1973-01-01\"))\n",
    "predict_period = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94e4bc-2525-4213-8e91-cc6c1fcae411",
   "metadata": {},
   "source": [
    "### ACTION: Try a new model with the intention to improve MAPE Error:\n",
    "    - Add a new model (see [Darts Models API](https://unit8co.github.io/darts/#forecasting-models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762234e3-22fa-430a-84a5-6c8721e0edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here:\n",
    "from darts.models import LinearRegressionModel\n",
    "model = LinearRegressionModel(lags=50)\n",
    "\n",
    "model.fit(training)\n",
    "forecast = model.predict( predict_period )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e78f05f-ecdc-4fbf-a151-367c43583968",
   "metadata": {},
   "source": [
    "<details><summary><span style=\"color:red\">&#x1F6C8; Help</span> (Use this only as a last resort!!)</summary>\n",
    "\n",
    "- Take a read of: https://unit8co.github.io/darts/generated_api/darts.models.forecasting.linear_regression_model.html\n",
    "- You should only need the `lags=...` parameter for the model. Try different `lags` values until you get a lower MAPE error than 4.16%.\n",
    "\n",
    "```python\n",
    "from darts.models import LinearRegressionModel\n",
    "# from darts.models import ( ExponentialSmoothing, FFT, AutoARIMA, \n",
    "#                          Theta, ARIMA, RegressionModel )\n",
    "# from darts.utils.utils import ModelMode, SeasonalityMode\n",
    "# from darts.models import NBEATSModel, XGBModel\n",
    "# from darts.models.forecasting.lgbm import LightGBMModel\n",
    "```\n",
    "\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58df5b-6eb7-48dc-9e37-dfde8bee4fb9",
   "metadata": {},
   "source": [
    "- Once trained and forecast is predicted, plot and note the evaluation metric score(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228508be-81b8-45aa-94be-b8546f84ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ori = transformer.inverse_transform(validation.copy())\n",
    "series_ori = transformer.inverse_transform(series.copy())\n",
    "forecast_ori = transformer.inverse_transform(forecast.copy())\n",
    "new_forecast = model.predict(n=len(series))\n",
    "new_forecast_ori = transformer.inverse_transform(new_forecast.copy())\n",
    "\n",
    "_plot_milk(series_ori, new_forecast_ori, validation_ori, target_column_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798e9c7-4b02-4ac6-8db1-a68617182bb8",
   "metadata": {},
   "source": [
    "### Q: Make a note of which `model` and `parameters` you tried and the `MAPE %` score. Is it better than the existing model at 4.16%?\n",
    "- For MAPE, we are looking for the smallest positive % error (close to zero).\n",
    "\n",
    "Ans: Linear regression model, lags = 50, MAPS = 2.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dcf017-d8cb-4470-86cc-b560154b517f",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc27d8a-88b4-4a72-997f-604160a44f5b",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "## Task 3: Let's add Feature Engineering - Milk produced by cows does not endlessly grow forever.. so let's reduce that in the later years:\n",
    "\n",
    "**Question: Can we integrate our domain knowledge about cows and milking into the model? Then further test the model.**\n",
    "\n",
    "Let's add:\n",
    "- a tapered curve -- i.e. the milk produced by cows does not endlessly grow forever.. so let's reduce that in the later years. Note: we can see that the data-trend is slowing in the later 5 years.\n",
    "\n",
    "Let's apply a function to taper the curve as time passes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a42580e-3a0f-480f-850c-0a8f3ff090e5",
   "metadata": {},
   "source": [
    "- By example, we can change the taper a line as below.\n",
    "    - Note the transform formula:  $x^{0.8}$\n",
    "    - And the inverse formula:  $x^{1/0.8}$ - which is used to correct it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4639cd-6e7c-4c4e-aeff-b10c6b5b7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.utils.timeseries_generation import linear_timeseries\n",
    "from darts.dataprocessing.transformers import Mapper, InvertibleMapper\n",
    "\n",
    "\n",
    "def _example_plot(_modifier):\n",
    "    lin_series = linear_timeseries(start_value=0, end_value=2, length=10)\n",
    "    f = InvertibleMapper(\n",
    "        fn=lambda x: x**_modifier,\n",
    "        inverse_fn=lambda x: np.power(y, 1/_modifier),\n",
    "    )\n",
    "    func = f.transform(lin_series)\n",
    "    \n",
    "    lin_series.plot(label=\"original\")\n",
    "    func.plot(label=\"func\")\n",
    "    plt.legend()\n",
    "    print(_modifier)\n",
    "\n",
    "_example_plot(_modifier=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed5023-e5ad-45ea-be5b-e54d147ae80f",
   "metadata": {},
   "source": [
    "- Note, our transformed data is less than 1.\n",
    "    - For $x<1$ the exponental function $x^{2}$ has a reducing effect.\n",
    "    - For $x>1$ the exponental function $x^{2}$ has an increasing effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecdf6ba-c661-4f29-9495-10e468bc398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 1.5\n",
    "i0, i1 = 0.9, 1.1\n",
    "print(f'For example:\\n\\t[below 1] {i0}^{e} = {i0**e:.4f} \\n\\t[above 1] {i1}^{e} = {i1**e:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd97c84-3c67-433e-b0c5-9a72717df40f",
   "metadata": {},
   "source": [
    "- Check the function inverse works correctly::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a55c4-07d0-41d0-9f29-fafb02a4a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = 10\n",
    "y = x **1.2\n",
    "np.power(y, 1/1.2) == x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9c38b-1061-4428-b8e6-1693e7cab34d",
   "metadata": {},
   "source": [
    "### Define and Apply the Taper transform function: using `modifier=1.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00947271-91a6-4047-8046-1fc725533b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_taper( taper_curve_function, training, split_pos=-36):\n",
    "    func = taper_curve_function.transform(training[-36:])\n",
    "    early = training[:-36]\n",
    "    func = TimeSeries.from_dataframe(pd.concat([early.to_dataframe(), func.to_dataframe()]))\n",
    "    return func\n",
    "taper_curve_function = InvertibleMapper(\n",
    "    fn=lambda x: x**1.2,\n",
    "    inverse_fn=lambda x: np.power(x, 1/1.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb86e0-eba7-437b-a097-5d8689fed626",
   "metadata": {},
   "source": [
    "- Get a fresh set of data, and apply the transform to the end of the training data:\n",
    "    - This will modify the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722de1a-dd38-4b8f-af71-26d97e8f58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset = MonthlyMilkIncompleteDataset\n",
    "series, transformer = collect_preprocessed_dataset(get_dataset)\n",
    "\n",
    "training, validation = series.split_before(pd.Timestamp(\"1973-01-01\"))\n",
    "new_training = custom_taper( taper_curve_function, training, split_pos=-36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7afb205-e434-44f1-a71d-021fa375213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_tapered_training_data(series, new_training, validation):\n",
    "    series.plot(label=\"original\", lw=1)\n",
    "    new_training[-36:].plot(label=\"taper_curve_function on training\", lw=1, color='red', ls='dashed')\n",
    "    validation.plot(label=\"validation\", lw=3, color='green', ls='dotted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "_plot_tapered_training_data(series, new_training, validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deab079-aa44-4fba-ad2c-9aa3ae39919e",
   "metadata": {},
   "source": [
    "- Confirm the inverse function works correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2048367-3dd4-4ac2-a2f3-cbcefdec597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_inverse_taper( taper_curve_function, new_training, validation, split_pos=-36):\n",
    "    func = taper_curve_function.inverse_transform(new_training[split_pos:])\n",
    "    early = new_training[:split_pos]\n",
    "    func = TimeSeries.from_dataframe(pd.concat([early.to_dataframe(), func.to_dataframe()]))\n",
    "    return func\n",
    "\n",
    "series.plot(label=\"original\")\n",
    "new_training.plot(label=\"transformed taper (training)\", ls='dotted')\n",
    "\n",
    "func = custom_inverse_taper( taper_curve_function, new_training, validation, split_pos=-36)\n",
    "func.plot(label='inversed taper (training)')\n",
    "print(f'RMSE: {rmse(func, series):.9f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca72b97-33f7-4b11-86dc-2c0f0efe79ff",
   "metadata": {},
   "source": [
    "### ACTION: Fit the Model to the new Data and Compare MAPE %:\n",
    "- Add your best model so far here (either ExponentialSmoothing, or your new variant), to compare its `MAPE %`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895544c-dfef-4ebd-bcba-15050c0211e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here:\n",
    "model = LinearRegressionModel(lags=50)\n",
    "\n",
    "model.fit(new_training)\n",
    "forecast = model.predict( predict_period )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca97c45-87b9-4571-a376-9a068fa4898f",
   "metadata": {},
   "source": [
    "- Plot and show the model evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5cce6-90be-4791-9133-4a489b03f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ori = transformer.inverse_transform(validation.copy())\n",
    "series_ori = transformer.inverse_transform(series.copy())\n",
    "forecast_ori = transformer.inverse_transform(forecast.copy())\n",
    "new_forecast = model.predict(n=len(series))\n",
    "new_forecast_ori = transformer.inverse_transform(new_forecast.copy())\n",
    "\n",
    "_plot_milk(series_ori, new_forecast_ori, validation_ori, target_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a7ee8-571f-4211-af77-b413f49b7d1e",
   "metadata": {},
   "source": [
    "- Monitor the RMSE Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ce819-7655-49f2-8742-0971643f4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score = rmse(forecast_ori, validation_ori)\n",
    "_display_rmse(rmse_score)\n",
    "\n",
    "rmse_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286f821-76d0-42ab-b891-b1341b35ec39",
   "metadata": {},
   "source": [
    "### Q: Did the RMSE Score improve with the new training curve? \n",
    "\n",
    "- Ans: No\n",
    "\n",
    "### Q: What is the difference in RMSE Error for `Milk Pounds per Cow per Month` between this trained model and the previous? Better or worse?\n",
    "\n",
    "- Ans: Worse, it's increase the error by 0.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd89cc1-c577-4bc5-925d-f86fa5185093",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "##### Final steps: show the newly updated future forecast prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023eba3a-77e3-4c0d-9ddc-5e4af22c84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_forecast = model.predict(n=len(series))\n",
    "new_forecast_ori = transformer.inverse_transform(new_forecast.copy())\n",
    "prediction_timestamp = '1980-09-01'\n",
    "pred_value = new_forecast_ori.to_dataframe().loc[prediction_timestamp]\n",
    "series_ori = transformer.inverse_transform(series.copy())\n",
    "validation_ori = transformer.inverse_transform(validation.copy())\n",
    "\n",
    "_plot_milk_with_prediction(series_ori, new_forecast_ori, validation_ori, pred_value, prediction_timestamp, target_column_name)\n",
    "plt.gcf().set_size_inches(12, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb146e-2759-4d71-9c78-2297afbc4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_score = mape(new_forecast_ori, validation_ori)\n",
    "pred_value, e_upper, e_lower = pred_value, pred_value * (1-(mape_score/100)), pred_value * (1+(mape_score/100))\n",
    "_plot_box_error(series_ori, prediction_timestamp, pred_value, e_upper, e_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770b285-036b-4f53-8a70-a3e729c92be0",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# \n",
    "# Part 2 - Global Forecasting Modeling of independent multi-series forecasting.\n",
    "\n",
    "Global forecasting, involves building a single predictive model that considers all time series simultaneously. It attempts to capture the core patterns that govern the series, thereby mitigating the potential noise that each series might introduce. This approach is computationally efficient, easy to maintain, and can yield more robust generalizations across time series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6536d4-23da-4eca-baff-26a8bb35d89e",
   "metadata": {},
   "source": [
    "## Task 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de84594-d1a6-46fd-b9a8-a496e1564b2c",
   "metadata": {},
   "source": [
    "#### Influenza Like Illness Dataset\n",
    "ILI describes the number of patients seen with influenzalike illness and the total number of patients. It includes weekly data from the Centers for Disease Control and Prevention of the United States from 1997 to 2022.\n",
    "\n",
    "##### Components Descriptions:\n",
    "- % WEIGHTED ILI: Combined state-specific data of patients visit to healthcare providers for ILI reported each week weighted by state population\n",
    "- % UNWEIGHTED ILI: Combined state-specific data of patients visit to healthcare providers for ILI reported each week unweighted by state population\n",
    "- AGE 0-4: Number of patients between 0 and 4 years of age\n",
    "- AGE 25-49: Number of patients between 25 and 49 years of age\n",
    "- AGE 25-64: Number of patients between 25 and 64 years of age\n",
    "- AGE 5-24: Number of patients between 5 and 24 years of age\n",
    "- AGE 50-64: Number of patients between 50 and 64 years of age\n",
    "- AGE 65: Number of patients above (>=65) 65 years of age\n",
    "- ILITOTAL: Total number of ILI patients. For this system, ILI is defined as fever (temperature of 100°F [37.8°C] or greater) and a cough and/or a sore throat\n",
    "- NUM. OF PROVIDERS: Number of outpatient healthcare providers\n",
    "- TOTAL PATIENTS: Total number of patients\n",
    "\n",
    "##### References:\n",
    "1. https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html\n",
    "2. https://www.cdc.gov/flu/weekly/overview.htm#Outpatient\n",
    "3. https://arxiv.org/pdf/2205.13504.pdf\n",
    "4. https://gis.cdc.gov/grasp/fluview/FluViewPhase2QuickReferenceGuide.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8734c8-5d3d-4a81-bce7-2fbddb03d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import MissingValuesFiller\n",
    "from darts.datasets import WeatherDataset, ILINetDataset\n",
    "\n",
    "series = ILINetDataset().load()\n",
    "print(series.to_dataframe().columns.tolist())\n",
    "filler = MissingValuesFiller()\n",
    "series = filler.transform(series, method=\"quadratic\")\n",
    "display(series.to_dataframe().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a626a7c-9b05-4738-bb02-a676cc68467a",
   "metadata": {},
   "source": [
    "#### Limited Dataset:\n",
    "- Due to the time to train the model, we will select just a small amount of data:\n",
    "    - 200 rows\n",
    "    - 8 Time Series\n",
    "    - Forecast 12 time-steps (weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc81a5-830e-41ef-81f5-92c605d0abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['T (degC)', 'p (mbar)', 'rh (%)', 'rain (mm)']\n",
    "#columns = ['TOTAL PATIENTS', 'NUM. OF PROVIDERS', 'ILITOTAL']\n",
    "columns = ['% WEIGHTED ILI', '%UNWEIGHTED ILI', 'AGE 0-4', 'AGE 5-24', 'AGE 65', 'ILITOTAL', 'NUM. OF PROVIDERS', 'TOTAL PATIENTS']\n",
    "series = series[columns]\n",
    "# train, val = series.split_before(0.8)\n",
    "train, val = series[:208], series[208:220] # 4 Years x52=208 / 3 months x4=12\n",
    "print('Time Series shapes - train:\\t', train.shape,'\\tval:\\t', val.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f1fdc-8b72-4867-bb5c-f9d4f250e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "transformer = Scaler()\n",
    "train_transformed = transformer.fit_transform(train)\n",
    "val_transformed = transformer.transform(val)\n",
    "series_transformed = transformer.transform(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e070-8be9-4aa4-9d1f-60041cb597f9",
   "metadata": {},
   "source": [
    "### ACTION: Fit the LSTM Model:\n",
    "- [Docs API for RNN Forecasting](https://unit8co.github.io/darts/generated_api/darts.models.forecasting.rnn_model.html#darts.models.forecasting.rnn_model.RNNModel.fit)\n",
    "    - Try 20, 50 epochs or more depending on time available.\n",
    "    - More epochs (rounds of model fitting using the training data) will tend to improve the performance; as will more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fccd615-3330-410b-8971-7e9e9c006d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from darts.models import RNNModel\n",
    "\n",
    "# Instantiate and train the RNN model\n",
    "model = RNNModel(\n",
    "    model=\"LSTM\", #'RNN' or 'GRU' or 'LSTM'\n",
    "    input_chunk_length=12,\n",
    "    output_chunk_length=len(val), #Predict for the length of the validation.\n",
    "    n_epochs=50,\n",
    "    random_state=0,\n",
    "    # hidden_dim=25,\n",
    "    # n_rnn_layers=5,\n",
    "    # dropout=0,\n",
    "    # batch_size=32,\n",
    "    # optimizer_kwargs={\"lr\": 1e-3},\n",
    "    # log_tensorboard=True,\n",
    "    # training_length=24,\n",
    "    # force_reset=True,\n",
    "    # save_checkpoints=True,\n",
    ")\n",
    "model.fit(\n",
    "    train_transformed,\n",
    "    # future_covariates=covariates,\n",
    "    # val_series=val_transformed,\n",
    "    # val_future_covariates=covariates,\n",
    "    # verbose=True,\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "prediction = model.predict(n=len(val_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803ec93c-5754-4540-ad9c-85358c9cda01",
   "metadata": {},
   "source": [
    "##### Calculate Forecast Performance Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb05eab5-0860-4efc-80c8-7950a831f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = _display_prediction_evaluations(series_transformed, train_transformed, val_transformed, prediction, sharexy=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad361edf-7426-4493-98db-d0b3d544dc4b",
   "metadata": {},
   "source": [
    "### ACTION: Calculate the Mean MASE Error for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0020d40-1a4e-4312-af84-adbd1c3947b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here:\n",
    "df_results\n",
    "print(df_results['MASE'].mean())\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560edff-893b-4534-9241-f6881af8adfa",
   "metadata": {},
   "source": [
    "### Q: Note down the Mean MASE Error:\n",
    "\n",
    "Ans: 11.868913570568523"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd9ee29-9bdd-4334-86b5-4c391f3a745e",
   "metadata": {},
   "source": [
    "## \n",
    "## Task 2: Local Forecasting - Applied separately, using univariate Exponential Smoothing modeling:\n",
    "- Now apply separately to each univariate component of the multivariate time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c3362c-4329-4ee3-8b9c-12c25f6b9c3b",
   "metadata": {},
   "source": [
    "### ACTION: Fit the ExponentialSmoothing Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920de811-3251-4939-b757-9bfe58862ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import ExponentialSmoothing\n",
    "\n",
    "predictions = {}\n",
    "for component in train_transformed.components:\n",
    "    model = ExponentialSmoothing()\n",
    "    model.fit(train_transformed[component])\n",
    "    predictions[component] = model.predict(n=len(val_transformed[component]))\n",
    "    \n",
    "df_results = _display_prediction_evaluations(series_transformed, train_transformed, val_transformed, prediction, sharexy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6746c8f-3f6f-4f1c-b08a-6a26cbba51f5",
   "metadata": {},
   "source": [
    "### ACTION: Calculate the Mean MASE Error for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9227b-eb0d-4794-b744-4c305970af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here:\n",
    "df_results\n",
    "print(df_results['MASE'].mean())\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a05be00-08b1-454a-9e20-e63bd5a9cfa2",
   "metadata": {},
   "source": [
    "### Q: Note down the Mean MASE Error:\n",
    "\n",
    "Ans: 11.868913570568523"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0deff-b840-4a8f-9a92-5662bcc47ab9",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "<p style=\"text-align:center;\">That's it! Congratulations! <br> \n",
    "    Now, call an LA to check your solution. Then, upload your code on MyCourses.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd933f-c379-44fb-a758-f80145b54bf5",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Homework on your Laptop for next week\n",
    "## Set-up GPU Acceleration for Models: - Prerequisite Installation of CUDA Toolkit (e.g. v12.6) and PyTorch: (takes 1 hour!)\n",
    "- Next week may require fine-training models, and GPU acceleration will speed up your training time (e.g. from 10 mins to 1 min).\n",
    "- If you have time before end of class, you can try to check / set-up a desktop machine in the Lab (in preparation for next week).\n",
    "## Step 1: - Check Torch & CUDA:\n",
    "```python\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "> # True or False. If True, no need to install CUDA Toolkit or PyTorch:\n",
    "```\n",
    "## Step 2: - Check Available Versions for Compatibility:\n",
    "- `Go to the PyTorch Install Guide Page:` - https://pytorch.org/get-started/locally/\n",
    "    - Find compatible CUDA Toolkit version - 11.8, 12.4, 12.6 (for NVIDIA GPU)  or ROCm (for AMD GPU).\n",
    "    - If you have MacOS, then \"CPU\" acceleration is the remaining option for the install command.\n",
    "    - **Before installing check your CUDA Toolkit version**:\n",
    "## Step 3: - Check Existing installation of CUDA Toolkit:\n",
    "- Check whether your device has a NVIDIA GPU or an AMD GPU (or no GPU).\n",
    "- Open your `\"Add or Remove Programs\"` in Windows (or search Apt-Get in Linux), and search for \"CUDA Toolkit\":\n",
    "    - Check for a compatibile version already installed (e.g. 11.8, 12.4, 12.6) (or appropriate for ROCm).\n",
    "    - `If already installed`, proceed to install PyTorch.\n",
    "    - `If no compatibile version installed`, then install as follows: (~3GB or more).\n",
    "        - https://developer.nvidia.com/cuda-toolkit-archive\n",
    "            - e.g. https://developer.nvidia.com/cuda-12-6-0-download-archive\n",
    "        - (latest verion and its install guide is here, but may not be compatible with PyTorch: https://developer.nvidia.com/cuda-downloads)\n",
    "## Step 4: - Install Compatible PyTorch Version:\n",
    "- Once a compatible CUDA Toolkit version is installed, install PyTorch\n",
    "    - Now install PyTorch via the command you selected earlier. (~2.5 GB for Torch pip package)\n",
    "        - e.g. `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126`\n",
    "- After the install is finished, Check `Step 1` again.\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab049606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "--index-url https://download.pytorch.org/whl/cu126"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2273824,
     "datasetId": 1340957,
     "sourceId": 2232033,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.354191,
   "end_time": "2025-02-26T14:13:59.772532",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-26T14:13:47.418341",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
