{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://www.ict.mahidol.ac.th/en/\" target=\"_blank\">\n",
    "    <img src=\"https://www3.ict.mahidol.ac.th/ICTSurveysV2/Content/image/MUICT2.png\" width=\"400\" alt=\"Faculty of ICT\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "# Lab10: Introduction to Time Series Modeling - Tutorial\n",
    "\n",
    "Time Series modeling is an supervised learning technique for forecasting (generating a future outcome) by using historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.metrics import (\n",
    "    coefficient_of_variation,\n",
    "    mae,\n",
    "    mape,\n",
    "    #marre,\n",
    "    mase,\n",
    "    mse,\n",
    "    rmse,\n",
    "    ope,\n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Univariate Forecasting: - ARIMA - Forecast a future point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from darts.datasets import AirPassengersDataset\n",
    "\n",
    "y = AirPassengersDataset().load().to_dataframe()\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Forecasting with Seasonal-Trend decomposition using LOESS (STL):\n",
    "- https://www.statsmodels.org/stable/examples/notebooks/generated/stl_decomposition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "stl = STL(y, seasonal=13)\n",
    "res = stl.fit()\n",
    "fig = res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.forecasting.stl import STLForecast\n",
    "\n",
    "stlf = STLForecast(y[:-24], ARIMA, model_kwargs=dict(order=(1, 1, 0), trend=\"t\"))\n",
    "stlf_res = stlf.fit()\n",
    "forecast = stlf_res.forecast(24)\n",
    "\n",
    "plt.plot(y[:-24], label='train')\n",
    "plt.plot(forecast, label='forecast')\n",
    "plt.plot(y[-24:], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics import r2_score\n",
    "\n",
    "r2_score(TimeSeries.from_values(y[-24:].to_numpy()), TimeSeries.from_values(forecast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Forecasting with Exponential Smoothing:\n",
    "\n",
    "Holtâ€™s Winters Seasonal Exponential Smoothing including a trend component and a seasonal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "\n",
    "model = ExponentialSmoothing(\n",
    "    y[:-24],\n",
    "    # seasonal_periods=60,\n",
    "    trend=\"mul\", # mul or add\n",
    "    seasonal=\"add\", # mul or add\n",
    "    use_boxcox=True,\n",
    "    initialization_method=\"estimated\",\n",
    ").fit()\n",
    "\n",
    "forecast = model.forecast(24) \n",
    "\n",
    "\n",
    "plt.plot(y[:-24], label='train')\n",
    "plt.plot(forecast, label='forecast')\n",
    "plt.plot(y[-24:], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "r2_score(TimeSeries.from_values(y[-24:].to_numpy()), TimeSeries.from_values(forecast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Forecasting with LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = TimeSeries.from_dataframe(y)\n",
    "\n",
    "# Create training and validation sets:\n",
    "train, val = series[:-24], series[-24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale Transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "\n",
    "# Normalize the time series (note: we avoid fitting the transformer on the validation set)\n",
    "transformer = Scaler()\n",
    "train_transformed = transformer.fit_transform(train)\n",
    "val_transformed = transformer.transform(val)\n",
    "series_transformed = transformer.transform(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static Covariates:\n",
    "- Static covariates are characteristics of a time series / constants which do not change over time. When dealing with multiple time series, static covariates can help specific models improve forecasts. Darts' models will only consider static covariates embedded in the target series (the series for which we want to predict future values) and not past and/or future covariates (external data).\n",
    "- https://unit8co.github.io/darts/examples/15-static-covariates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "\n",
    "# create month and year covariate series\n",
    "year_series = datetime_attribute_timeseries(\n",
    "    pd.date_range(start=series.start_time(), freq=series.freq_str, periods=200),\n",
    "    attribute=\"year\",\n",
    "    one_hot=False,\n",
    ")\n",
    "year_series = Scaler().fit_transform(year_series)\n",
    "month_series = datetime_attribute_timeseries(\n",
    "    year_series, attribute=\"month\", one_hot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Standard Scaled Years:')\n",
    "display(year_series.to_dataframe())\n",
    "print('One hot encoded Months:')\n",
    "display(month_series.to_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add these new features as \"covariates\" (extra features) to the model, along with the target `Time Series data`:\n",
    "- Month as one-hot encoded features.\n",
    "- Year as numeric feature, standard scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = year_series.stack(month_series)\n",
    "cov_train, cov_val = covariates.split_after(val.start_time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from darts.models import RNNModel\n",
    "\n",
    "model = RNNModel(\n",
    "    model=\"LSTM\",\n",
    "    hidden_dim=20,\n",
    "    dropout=0,\n",
    "    batch_size=16,\n",
    "    n_epochs=50,\n",
    "    optimizer_kwargs={\"lr\": 1e-3},\n",
    "    model_name=\"Air_RNN\",\n",
    "    log_tensorboard=True,\n",
    "    random_state=42,\n",
    "    training_length=20,\n",
    "    input_chunk_length=14,\n",
    "    force_reset=True,\n",
    "    save_checkpoints=True,\n",
    ")\n",
    "\n",
    "model = model.fit(\n",
    "    train_transformed,\n",
    "    future_covariates=covariates,\n",
    "    val_series=val_transformed,\n",
    "    val_future_covariates=covariates,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = RNNModel.load_from_checkpoint(model_name=\"Air_RNN\", best=True)\n",
    "forecast = model.predict(n=24, future_covariates=covariates)\n",
    "print(forecast.shape)\n",
    "\n",
    "plt.plot(train_transformed.to_dataframe(), label='train')\n",
    "plt.plot(forecast.to_dataframe(), label='forecast')\n",
    "plt.plot(val_transformed.to_dataframe(), label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "r2_score(val_transformed, forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try changing Epochs to 20, 50 and more to observe the changes in R2_Scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# Part 2 - Data Exploration Steps for Time Series Models:\n",
    "- Largely these steps are required by Statistical models depending on `Autoregression` (ARIMA, VARIMA, VAR, etc).\n",
    "- They can be informative to understand the conditions of the data's correlations and dependencies over time to guide `ML-based modelling` choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset:\n",
    "Let's use the airline passengers dataset to illustrate these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.datasets import AirPassengersDataset\n",
    "\n",
    "y = AirPassengersDataset().load().to_dataframe()\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Stationarity - Testing & Transforms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test using Augmented Dickey-Fuller (ADF) inference test to confirm significant trend (`stationarity`), if so let's remove.\n",
    "- *Strictly necessary for autoregressive models: such as ARIMA, VARIMA, VAR.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(y)\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-Stationary to Stationary Transforms (`statsmodels -> detrend`)\n",
    "- https://www.statsmodels.org/stable/generated/statsmodels.tsa.tsatools.detrend.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.tsatools import detrend\n",
    "y_detrend = detrend(y, order=3, axis=0)\n",
    "plt.plot(y)\n",
    "plt.plot(y_detrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(y_detrend)\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a P-value below 0.05, we can consider the test result is significant. Now the data is \"stationary\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-Stationary to Stationary Transforms (`diff(y)`) - First order difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pd = y\n",
    "y_diff = y_pd.diff()\n",
    "plt.plot(y_pd, label='Y')\n",
    "plt.plot(y_diff, label='diff(Y)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-Stationary to Stationary Transforms (`diff(diff(Y))`) - Second Order Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pd = y\n",
    "y_diff = y_pd.diff().diff()\n",
    "# plt.plot(y_pd)\n",
    "plt.plot(y_pd, label='Y')\n",
    "plt.plot(y_diff, label='diff(diff(Y))')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(y_diff.dropna())\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-Stationary to Stationary Transforms (`diff(Log(y))`) - Log and Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pd = y\n",
    "y_log = np.log(y_pd)\n",
    "y_log_diff = y_log.diff()\n",
    "# plt.plot(y_pd)\n",
    "plt.plot(y_log, label='log(Y)')\n",
    "plt.plot(y_log_diff, label='diff(log(Y))')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(y_log_diff.dropna())\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-Stationary to Stationary Transforms (`helper function`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "sd = seasonal_decompose(y)\n",
    "_ = sd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(seasonal_decompose(y_pd).resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_decompose(y_pd).resid.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(seasonal_decompose(y_pd).resid.dropna())\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_detrend = seasonal_decompose(y_pd).resid.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Lag Features: Autocorrelation Factor (ACF) and Partial Autocorrelation Factor (PACF) Plots: \n",
    "\n",
    "> The value of PACF is to measure the correlational effect of lag on future predictions; which is the periodicity of cycles in the time series data. We look back at the historical data to predict the future data. A good choice here can improve the predictive performance of the your model.\n",
    "\n",
    "#### Requirements:\n",
    "\n",
    "\n",
    "##### Stationarity (As Above in Task 1):\n",
    "- In order to correctly evaluate PACF, we should ensure the (univariate) series is `stationary`.\n",
    "- Although not strictly required, later correlation-lags will be less sensitive. \n",
    "    - Evaluate whether the series is stationary (often not the case) using the ADF and KPSS tests.\n",
    "    - Convert `Non-Stationary` (univariate) series to `Stationary` by using `diff()` (within pandas), which calculates the derivative of the sequence. Sometimes we need the first deriviative (e.g. at order 1, `diff() once`) and sometimes we need more, e.g. order 2, `diff() twice`; sometimes it's not possible to achieve stationarity.\n",
    "- Once we have stationary time series data, we can correctly interpret the PACF.\n",
    "\n",
    "##### Intepretting Lag Feature Effects:\n",
    "- PACF expresses the `correlation` between a univariate variable (a time series, e.g. $y_t$) and its lagged variable (e.g. $y_{t-lag}$).\n",
    "- PACF excludes any effects of the intermediary lagged time steps (i.e. $y_t-1$, $y_t-2$, $y_t-3$, ... to $y_{t-(lag-1)}$).\n",
    "- `Correlation` between two variables indicates how much they change together, `a=[1,2,3]` with `b=[1,2,2.9]` is highly correlated for example, and a correlation test (such as Pearson's R) would calculate a high correlation score.\n",
    "- In PACF, we consider the true data e.g. `a=[10,20,30]` and lagged version (e.g. `lag=1`) of that data `b=[--,10,20]`. In this case the correlation is quite high (because the example is a linear line :-).\n",
    "- If we find a lag value (e.g. lag=1,2,3, etc.) that gives a `high correlation score` it indicates that this lag value is a good one (is helpful for predicting the true values).\n",
    "\n",
    "##### How to read the PACF plot:\n",
    "- `Y-axis` shows `correlation` score.\n",
    "- `X-axis` shows each `Lag` value, starting at 0 (only the original data) and the number you ask for (e.g. 5).\n",
    "- The `grey` area that starts from the left at `Lag=1` determines the `confidence intervals (CI)` (default is alpha=0.05, which is CI=95%).\n",
    "    - Btw, In PACF, the `grey area increases in size` as more comparisons that are made (from left to right). This is a probability correction activity (like a Bonferroni Correction for Family-wise Error); it reduces the random chance of the test having made  mistake (error), or us as the plot reader.\n",
    "- Any `Lag`-`Correlation` points that fall within that `grey` area are `insignificant` (statistically), and we can forget about that particular lag value as being important (for now).\n",
    "- The Granger Causality test (`statsmodels.tsa.stattools.grangercausalitytests`) will evaluate whether a single lagged series can predict the true series (via statistical significance testing).\n",
    "- Each of the lagged series (lag values) showing as significant (by Granger Test or by exceeding the 95% Confidence Intervals in the plot) can be used as predictors of the true series.\n",
    "\n",
    "> PACF is therefore a form of (independent-feature) feature selection, in order to help improve time series model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y)\n",
    "_ = plt.title('Airline Passenger Dataset:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "lags = [24, 60]\n",
    "for lag in lags:\n",
    "    print('Lag Parameter is: ',lag)\n",
    "    fig = plot_pacf( y_detrend , lags=lag, alpha=0.05, title='Partial Autocorrelation Factor (PACF)') \n",
    "    axs = fig.get_axes()\n",
    "    [ax.set_ylabel('Correlation Score') for ax in axs]\n",
    "    [ax.set_xlabel('Lag Value') for ax in axs]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection of PACF results:\n",
    "- Lag-independent negative correlations at months 2,3,6,7,8,13: - indicates decreased passengers on these months.\n",
    "- Lag-independent positive correlations at months 11,12: - indicates increased passengers on these months.\n",
    "- Lag-independent positive correlations at month 1: - indicates increasing trend of passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation Factor (ACF) Plots:\n",
    "- Autocorrelation Factor illustrates the dependent (correlated) relationship between each lag and its previous lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "lags = [24, 60]\n",
    "for lag in lags:\n",
    "    print('Lag Parameter is: ',lag)\n",
    "    fig = plot_acf( y_detrend , lags=lag, alpha=0.05, fft=True, title='Autocorrelation Factor (ACF)') \n",
    "    axs = fig.get_axes()\n",
    "    [ax.set_ylabel('Correlation Score') for ax in axs]\n",
    "    [ax.set_xlabel('Lag Value') for ax in axs]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection of ACF results:\n",
    "- A significant and positive (increasing) correlation at cycle periods of 11,12,13 months and at 1 month.\n",
    "    - Indicating at 1 month, trending upwards.\n",
    "    - Indicating at 11,12,13 months treading upwards on a yearly (11 to 13 month) basis: - Suggesting 3 months of the year are regularly high and trending upwards.\n",
    "- A significant and negative (decreasing) correlation at cycle periods of 4,5,6,7,8 months: - 5 months of the year are regularly low and have lessening correlation over time.\n",
    "- Overall, time-dependency correlations (and trends) are significant in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "<p style=\"text-align:center;\">That's it! Congratulations! <br>     \n",
    "    Now, let's move to today's Lab Assignment.</p>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
