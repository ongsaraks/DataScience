{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9494ae-e5af-4d80-8d62-55898cee295c",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://www.ict.mahidol.ac.th/en/\" target=\"_blank\">\n",
    "    <img src=\"https://www3.ict.mahidol.ac.th/ICTSurveysV2/Content/image/MUICT2.png\" width=\"400\" alt=\"Faculty of ICT\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "# Lab07: ML Basics: Regression\n",
    "\n",
    "This tutorial will provide hands-on practice in building regression models to predict using the real-world Melbourne House Prices dataset collected in 2017, by using multiple features from the dataset and including evaluating model performance using two error metrics. \n",
    "\n",
    "Furthermore, it will introduce key machine learning concepts such as feature engineering, model complexity trade-off to improve the error scores. You will learn how to expand feature sets, create polynomial features, interpret coefficients, assess feature importance; which will lead us towards smart algorithms that can manage this trade-off. The steps will show you how to use utilize core machine learning concepts including pipelines and cross-validation for robust model training and evaluation.\n",
    "\n",
    "\n",
    "## This tutorial will look at regression predictions (numeric outputs):\n",
    "* Create an interactive GIS map of the dataset, using Plotly.\n",
    "* Re-evaluate the (X) Distance -> Price (Y) prediction model. Measure its MAE and R² error scores.\n",
    "* See the effects of underfitting to the data in learning curves (due to a simple model), therefore we will increase model complexity.\n",
    "* Complexify our approach by expanding:\n",
    "    * (1) the number of features,\n",
    "    * Introduce a plot to show the model's error per feature (residual error plots with 0 error as the red line).\n",
    "    * (2) the feature representations using Polynomial equations to increase the number of model parameters, and the estimator function's expressiveness to the data.\n",
    "    * (3) find this can overfit our training data (via learning curves) at the expense of our testing data fit.\n",
    "    * Therefore we will need to choose smart algorithms when we complexify (which you will do shortly).\n",
    "* In the Lab 07 Assignment, you will use a smarter (more sophisticated) algorithm to model and predict the data, then display its predictions.\n",
    "\n",
    "Also:\n",
    "* Look at interpreting feature coefficients (with multi-feature / multivariate linear regression).\n",
    "* Look at feature importance - the importance of each feature upon the predictions, by scaling.\n",
    "* Introduce new concepts:\n",
    "    * Pipelines to handle scaling preprocessing steps \"automagically\";\n",
    "    * Cross-validation (CV K-folds) to calculate the learning curves, which will give an average error across the full dataset by evaluating several times.\n",
    "\n",
    "__Instructions:__\n",
    "1. Append your ID at the end of this jupyter file name. For example, ```ITCS227_Lab07_Assignment_6788123.ipynb```\n",
    "2. Complete each task in the lab.\n",
    "3. Once finished, raise your hand to call a TA.\n",
    "4. The TA will check your work and give you an appropriate score.\n",
    "5. Submit the source code to MyCourse as record-keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616cbdc-d9b5-490c-a880-5bf904194e22",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plotly is installed with Anaconda, if you need to install it seperately, see https://pypi.org/project/plotly/\n",
    "# Shap Values is installed separately, see: https://pypi.org/project/shap/\n",
    "# !pip install plotly shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f5e31-eabb-4065-990a-cb8d5b88ff6e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e660e7-0114-4367-8fb4-cd4ab443ed10",
   "metadata": {},
   "source": [
    "## 1. Load the dataset with a Numeric Target (Dataset for Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e88e0-562b-44c4-a877-0df45c2bb829",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Diabetes Dataset (Optional extra for your own investigation):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dac51-16b8-4888-88a4-a867497a1139",
   "metadata": {},
   "source": [
    "**Diabetes Dataset Description**\n",
    "\n",
    "* Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Data Set Characteristics:\n",
    "\n",
    "* Number of Instances: 442\n",
    "* Number of Attributes: First 10 columns are numeric predictive values\n",
    "* Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "* age age in years\n",
    "* sex\n",
    "* bmi body mass index\n",
    "* bp average blood pressure\n",
    "* s1 tc, total serum cholesterol\n",
    "* s2 ldl, low-density lipoproteins\n",
    "* s3 hdl, high-density lipoproteins\n",
    "* s4 tch, total cholesterol / HDL\n",
    "* s5 ltg, possibly log of serum triglycerides level\n",
    "* s6 glu, blood sugar level\n",
    "\n",
    "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of n_samples (i.e. the sum of squares of each column totals 1).\n",
    "\n",
    "Response Attribute Information:\n",
    "\n",
    "* For our tutorial, we will interpret:\n",
    "  * `y=0` value to mean there is no disease progression after 1 year.\n",
    "  * `y>0` means there has been a degree of disease progression (larger numbers mean larger progression).\n",
    "\n",
    "Source URL: https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "\n",
    "For more information see: Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) “Least Angle Regression,” Annals of Statistics (with discussion), 407-499. (https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d07eba-5c2c-45c1-96e9-570ec3a8997c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "# Load a dataset\n",
    "data = load_diabetes(scaled=False)\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['y'] = data.target # y = \"measure of disease progression one year after baseline\"\n",
    "\n",
    "features = ['bmi'] #  # Use only one feature: bmi - Body Mass Index\n",
    "target = ['y']\n",
    "\n",
    "print(\"Original DataFrame Info:\")\n",
    "print(df.info())\n",
    "print('Note: y is the target, which is a \"Measure of disease progression, one year after baseline measurement.\"')\n",
    "print('We will interpret a `y=0` value to mean there is no disease progression after 1 year. Whereas a `y>0` means there has been progression.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3fd6d-7201-4572-93de-803538c3b03b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Number of Records,  Features: ', df.shape)\n",
    "print('Head of dataframe, for two example records:')\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3dd68-6c65-49e3-b965-65a0cc0fb09b",
   "metadata": {},
   "source": [
    "### Melbourne House Prices Dataset: (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3555c9-7a61-4cd7-9b60-de530f07872b",
   "metadata": {},
   "source": [
    "Melbourne real estate is BOOMING. Can you find the insight or predict the next big trend to become a real estate mogul… or even harder, to snap up a reasonably priced 2-bedroom unit?\n",
    "\n",
    "**Content**\n",
    "- This is a snapshot of a dataset created by Tony Pino.\n",
    "- It was scraped from publicly available results posted every week from Domain.com.au. He cleaned it well, and now it's up to you to make data analysis magic. The dataset includes Address, Type of Real estate, Suburb, Method of Selling, Rooms, Price, Real Estate Agent, Date of Sale and distance from C.B.D.\n",
    "\n",
    "**Notes on Specific Variables**\n",
    "- Rooms: Number of rooms\n",
    "- Price: Price in dollars\n",
    "- Method: S - property sold; SP - property sold prior; PI - property passed in; PN - sold prior not disclosed; SN - sold not disclosed; NB - no bid; VB - vendor bid; W - withdrawn prior to auction; SA - sold after auction; SS - sold after auction price not disclosed. N/A - price or highest bid not available.\n",
    "- Type: br - bedroom(s); h - house,cottage,villa, semi,terrace; u - unit, duplex; t - townhouse; dev site - development site; o res - other residential.\n",
    "- SellerG: Real Estate Agent\n",
    "- Date: Date sold\n",
    "- Distance: Distance from CBD\n",
    "- Regionname: General Region (West, North West, North, North east …etc)\n",
    "- Propertycount: Number of properties that exist in the suburb.\n",
    "- Bedroom2 : Scraped # of Bedrooms (from different source)\n",
    "- Bathroom: Number of Bathrooms\n",
    "- Car: Number of carspots\n",
    "- Landsize: Land Size\n",
    "- BuildingArea: Building Size\n",
    "- CouncilArea: Governing council for the area\n",
    "\n",
    "**Acknowledgements**\n",
    "- This is intended as a static (unchanging) snapshot of https://www.kaggle.com/anthonypino/melbourne-housing-market. It was created in September 2017. Additionally, homes with no Price have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fce58f-e80f-45d3-a971-f23709eae9e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "def TIMESTAMP_FILENAME(): return time.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    \n",
    "def plotly_map(df, latlng_cols=('lat','lng'), z=None, custom_data_cols=[], custom_text=[], center_dict=dict(lat=13.6, lon=100.4), zoom=5, WRITE=False, WRITE_FN=None):\n",
    "    \"\"\" \n",
    "    @WRITE_FN - do not include extension - i.e. `.png` or `.html`, as both files will be written.\n",
    "    Docs:   https://plotly.com/python-api-reference/generated/plotly.express.density_mapbox.html\n",
    "            https://plotly.com/python/mapbox-density-heatmaps/\n",
    "    \"\"\"\n",
    "    pio.templates.default = 'plotly_white' # 'plotly_dark'\n",
    "    fig = px.density_mapbox(df, \n",
    "                            lat=latlng_cols[0], \n",
    "                            lon=latlng_cols[1], \n",
    "                            z=z,\n",
    "                            radius=5,\n",
    "                            center=center_dict, zoom=zoom,\n",
    "                            mapbox_style=[\"open-street-map\",'carto-darkmatter'][0],\n",
    "                            custom_data=custom_data_cols,\n",
    "                           )\n",
    "\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    if custom_text:\n",
    "        fig.update_traces(\n",
    "            hovertemplate=\"<br>\".join(custom_text)\n",
    "        )\n",
    "    fig.show(config={'displayModeBar': False} )\n",
    "    if WRITE:\n",
    "        if WRITE_FN != None and isinstance(WRITE_FN, str) and len(WRITE_FN)>4:\n",
    "            ofn = f'{WRITE_FN}_MapPlot_{TIMESTAMP_FILENAME()}'\n",
    "            fig.write_image(ofn+'.png')\n",
    "            fig.write_html(ofn+'.html', full_html=False, include_plotlyjs=False, include_mathjax=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab4fc7-4cdb-4539-a8e5-f196881ce444",
   "metadata": {},
   "source": [
    "#### Exploration Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52bb92-c89f-4474-b6bb-486ff21ce8c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load a real-world dataset (using the small-sampled Melbourne Housing dataset)\n",
    "try:\n",
    "    df = pd.read_csv('files/melb_data.csv').drop('Unnamed: 0',axis=1) # Try to use the local file\n",
    "except FileNotFoundError:\n",
    "    print(\"melb_data.csv not found locally.\")\n",
    "\n",
    "print(\"Original DataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "cols_to_use = ['Distance','Landsize','BuildingArea','Rooms', 'Bathroom', 'Price']\n",
    "\n",
    "print('Total Num of Records ',len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f080eb-3d95-4642-8f82-46bd43ebadeb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfm = df.dropna() # Drop NaNs for the visualization:\n",
    "plotly_map(dfm[ (dfm['Method']=='S') ] , \n",
    "           # Method: S - property sold ~~ This includes properties that were sold, and therefore includes its price at the time of sale.\n",
    "           # You could easily add more Pandas filters here to explore the data, such as dfm[ (dfm['Method']=='S') & (dfm['Price']<1000000)] \n",
    "           latlng_cols=('Lattitude','Longtitude'), \n",
    "           z='Price',\n",
    "           custom_data_cols=['CouncilArea',\n",
    "                             'Distance',\n",
    "                             'Landsize',\n",
    "                             'BuildingArea',\n",
    "                             'Rooms',\n",
    "                             'Bathroom',\n",
    "                             'Price'\n",
    "                           ], \n",
    "           custom_text=['Area: %{customdata[0]}',\n",
    "                        'Distance: %{customdata[1]}',\n",
    "                        'LS  / BA: %{customdata[2]}/%{customdata[3]}',\n",
    "                        'Bed / Bath: %{customdata[4]}/%{customdata[5]}',\n",
    "                        'Price AUD-$: %{customdata[6]:.,1f}'\n",
    "                            ],\n",
    "           center_dict=dict(lat=-37.814, lon=144.963),\n",
    "           zoom=9\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7465f158-39c5-4b76-9869-df0bc5b26d57",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "## 2. X -> Y Dataset Split:\n",
    "\n",
    "First we collect the `X` (inputs) and `y` (outputs) from the complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b139730d-3c32-4827-9f4f-863b275e8f2f",
   "metadata": {},
   "source": [
    "#### Get X-Y Data with Imputed Missing Values:\n",
    "- Fill in the missing values in the dataset, the `NaN` and `None` values. This only works for `numerical` features.\n",
    "    - `MICE` - **(Multivariate Imputation from Chained Equations):**\n",
    "        - This time we will use `MICE` to impute any missing values in the dataset, feature by feature.\n",
    "        - `MICE` works by predicting a Feature 1 (e.g. distance), according to the remaining features, (e.g. Bedrooms, Bathrooms, Land Size, etc.).\n",
    "            - For Feature 1, the MICE algorithm will look at all the remaining features (as X), and try to predict the best value to replace a missing value in feature 1 (as Y_Pred).\n",
    "            - The dataset already contains many Y_True values (for Feature 1). Because of this, most values are filled in.\n",
    "            - So MICE trains a regression model on the known Y_True values and only predicts the missing Y (Feature 1) values to insert (impute) into the dataset.\n",
    "            - It is possible to measure the impact of any imputation algorithm, by comparing `End-to-End Machine Learning task's` prediction results for different imputation methods.\n",
    "            - (Learn more on this topic in an Advanced Statistics subject.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08022537-2a53-43e0-a776-d503be24b4ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "def get_some_data(data:pd.DataFrame, features:list, target:list):\n",
    "    y = data[target].to_numpy()\n",
    "    X = data[features].to_numpy()\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imputed_X = imp.fit(X).transform(X) # This uses MICE - Multivariate Imputation from Chained Equations.\n",
    "                                        # Multivariate imputer that estimates each feature from all the others. \n",
    "                                        # A strategy for imputing missing values by modeling each feature with \n",
    "                                        # missing values as a function of other features in a round-robin fashion.\n",
    "    return imputed_X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf2ae7-c65a-4c86-a4b1-970e47d2ff4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"First, let's separate the X features from the Y target feature(s)\\n\")\n",
    "\n",
    "target = ['Price']\n",
    "features = cols_to_use[:-1]\n",
    "\n",
    "X, y = get_some_data( df, features, target )\n",
    "\n",
    "y_min = y.min()\n",
    "y_max = y.max()\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f'X : {features}')\n",
    "print(f'y : {target}')\n",
    "print(f'{target} - Target feature value range (Min-Max): {y_min:,.1f}-{y_max:,.1f}')\n",
    "display(df[features+target].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0508190-54fc-401a-ba51-a06973fc9237",
   "metadata": {},
   "source": [
    "#### Train/ Test Splits:\n",
    "Later, we will split the full dataset into `train set` and `test set`.\n",
    "\n",
    "In Lab 7, we will be using two new techniques:\n",
    "* `Feature Scaling of X` and\n",
    "* `K-folds Cross Validation` to make the `Train/ Test split` \"auto-magically\" (we can learn more detail about how this works and why it is great for evaluating models later on).\n",
    "\n",
    "Each time we `fit / predict` a model to `(1) train` and `(2) test (or evaluate)` the **estimator function** - our model we will handle the spliting. As before, the `test set` will represent how our model might perform on real-world input data.\n",
    "\n",
    "So, at this stage we only have `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27b5879-fe5f-4618-ab8f-16bb97512745",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "## 3. Linear Regression Fit/Predict:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5452d5-e33c-4d23-ae9a-663487a6b4ac",
   "metadata": {},
   "source": [
    "### 3.1 Univariate (Single Feature) Number Prediction:\n",
    "\n",
    "Last week we used only `Distance->Price` (`X->Y`) to get a prediction.\n",
    "\n",
    "Let's repeat that and collect the errors summary to remind ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ee275-dd30-4ddf-ab7a-fd3d34b29634",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _extract_model_parameters(estimator, features):\n",
    "    intercept = estimator.intercept_[0]\n",
    "    coefficients = estimator.coef_[0]\n",
    "    \n",
    "    print(\"Intercept:\", intercept)\n",
    "    print(\"Coefficients:\", list(coefficients))\n",
    "    sf = 1\n",
    "    \n",
    "    model_params = [coefficients, intercept]\n",
    "    coef_strings = [f'{round(tup[0],sf):,.1f} * X{tup[1]}({tup[2]})' for tup in zip(model_params[0], range(1,len(features)+1), features ) ]\n",
    "    eq = f'{model_params[1]:,.1f} + '+(' + '.join( coef_strings ))+f\" ({sf} s.f.)\"\n",
    "    eq = f'f( X ) = {eq}'\n",
    "    return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92943dc0-310a-4e64-b43a-ff3ac1a335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X, y = get_some_data( df, ['Distance'], target )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0) # Split into 85% training and 15% testing data\n",
    "\n",
    "estimator = LinearRegression()\n",
    "estimator.fit(X_train, y_train)\n",
    "input_to_predict =  X_train[0].reshape(1, -1)\n",
    "y_pred = estimator.predict( input_to_predict )\n",
    "y_true = y_train[0]\n",
    "error = y_true - y_pred\n",
    "print(f'For this data-point {dict(zip(features,input_to_predict[0]))} in the Price prediction (estimate) had an AUD $ {error[0][0]:,.2f} (error)')\n",
    "# Take out the integer value (from the numpy arrays. In this case, the value is wrapped by two arrays, hence [0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1e718-9adb-4d09-9c47-007ab49a0de4",
   "metadata": {},
   "source": [
    "* Let's measure Mean Absolute Error again, to get the average prediction price error in AUD-$.\n",
    "\n",
    "* Let's also introduce $R^2$ (R-squared or R^2):\n",
    "    > R-squared represents the proportion of the variance in our target (`Price feature`) that is predictable from the input variables (`X features`).\n",
    "    >    - `R2= 0.70`  -- Means -- `70% of variation` in `Price` is explained by the estimator function trained on the input `X features`.\n",
    "    >    - However, `30% remains unexplained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c76f3-836a-4483-a252-4a1058c5c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "y_pred = estimator.predict(X_test)\n",
    "print(f\"mean_absolute_error: {mean_absolute_error(y_test, y_pred):,.2f}\")\n",
    "print(f\"r2_score: {r2_score(y_test, y_pred):,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a5042-4430-4c17-9fc7-4a5a088770ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Here's the estimator function found by Linear Regression: \\n\")\n",
    "# _extract_model_parameters(estimator, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4faa35f-45a6-45e5-bfec-b1a72b8073f4",
   "metadata": {},
   "source": [
    "### 3.2 Plot individual Error Distances:\n",
    "\n",
    "* Another look at error distances for each point, to decide if some inputs (X) to the model perform better than others.\n",
    "* Mostly we are interested in the `Test set` performance results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf49ea9-959c-4dd5-9f3a-41005c738722",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _plot_regression_distance_errors( X_set, y_set, estimator, input_feature_name='' ):\n",
    "    y_pred = estimator.predict( X_set )\n",
    "    # Plot data and individual distance errors\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for i in range(len(X_set)):\n",
    "        plt.plot([X_set[i], X_set[i]], [y_set[i], y_pred[i]], color=\"gray\", lw=0.75, linestyle=\"dashed\")\n",
    "    plt.scatter(X_set, y_set, color=\"blue\", label=\"Actual values\", s=10)\n",
    "    plt.plot(X_set, y_pred, color=\"red\", label=\"Regression line\")\n",
    "    \n",
    "    # Plot individual errors as vertical lines\n",
    "    plt.xlabel(f\"Input {input_feature_name} (X)\")\n",
    "    plt.ylabel(\"Target (y)\")\n",
    "    plt.title(f\"Linear Regression with Individual Errors (n={len(X_set):,})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    from matplotlib.lines import Line2D\n",
    "    error_line = Line2D([], [], color='gray', linestyle='--', lw=0.5, label='Error distance per point')\n",
    "    plt.legend(handles=[*plt.gca().get_legend_handles_labels()[0], error_line])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb247f2-df16-44b8-83be-60059feddd65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "_plot_regression_distance_errors( X_test, y_test, estimator, input_feature_name=features[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c906e912-e5fe-4ab4-a5b7-16046728b6c3",
   "metadata": {},
   "source": [
    "## 4. Learning Curves\n",
    "\n",
    "The goal of the `learning curve` plot is to visualize whether the model algorithm is `overfitting` or `underfitting` the dataset.\n",
    "\n",
    "Then we can decide the next step to improve the model: either to `simplify` or `complexify`.\n",
    "\n",
    "**How this works?**\n",
    "\n",
    "Fit/ Predict the model on different sizes of the dataset, to see how the models performs. Alternatively, if using mini-batch learning then we measure error per epoch or training cycle (such as neural network training or the SGDRegressor).\n",
    "- If the error line is falling as data size increase (`X-axis`), then more data may continue to improve model performance.\n",
    "- If the error line is stationary and `Train / Valid` are approx equal and the error is high,\n",
    "    - Then the model is `underfitting`\n",
    "- If the error line is stationary and `Train / Valid` are approx equal and the error is low,\n",
    "    - The model is `generalized`.\n",
    "- If the error line for `Train` is lower than `Valid`,\n",
    "    - The model is `overfitting` the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f06e2a-0c0d-41f7-91f9-14a1f672fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_learning_curve(estimator, train_sizes, train_scores, valid_scores, metric='MAE', plt_text='', ax=None):\n",
    "    train_errors = -train_scores.mean(axis=1)\n",
    "    valid_errors = -valid_scores.mean(axis=1)\n",
    "    ax = plt.gca() if not ax else ax\n",
    "    ax.plot(train_sizes, train_errors, \"r-+\", linewidth=2, label=\"train\")\n",
    "    ax.plot(train_sizes, valid_errors, \"b-\", linewidth=3, label=\"valid\")\n",
    "    ax.set_xlabel(\"Training set size\")\n",
    "    ax.set_ylabel(f'{metric}')\n",
    "    # plt.gca().set_xscale(\"log\", nonpositive='clip')\n",
    "    ax.grid()\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_ylim(bottom=0, top=1.25*max([max(train_errors), max(valid_errors)]))\n",
    "    ax.set_title(f'{estimator.__class__.__name__}\\n{plt_text}', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72336294-2293-4108-aa43-8832ee328478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve # New - for evaluating errors and then visualizing later.\n",
    "from sklearn.preprocessing import StandardScaler   # New - for preprocessing.\n",
    "from sklearn.pipeline import Pipeline              # New - used to preprocess and fit/predict data automatically and correctly, handled by SciKit Learn.\n",
    "\n",
    "X, y = get_some_data( df, ['Distance'], target )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0) # Split into 85% training and 15% testing data\n",
    "\n",
    "estimator = LinearRegression()\n",
    "pipeline = Pipeline([\n",
    "    # ('scaler', StandardScaler()),  # StandardScaler\n",
    "    ('regressor', estimator)       # Regressor estimator\n",
    "])\n",
    "\n",
    "train_sizes, train_scores, valid_scores = learning_curve( pipeline, \n",
    "                                                        X_train, y_train, \n",
    "                                                        train_sizes=np.linspace(0.01, 1.0, 50), # 50 size intervals, from 1% to 100%\n",
    "                                                        cv=5,     # CV=5 means  Train = 80%  , Test = 20%.\n",
    "                                                                  # CV=10 means Train = 90%  , Test = 10%.\n",
    "                                                                  #   - The fit/predict is repeated 5 times with random samples taken from X/Y.\n",
    "                                                                  #   - The resulting error is the average across all 5 trials; so a smoother and fairer result than CV=1 , which is hold-out.\n",
    "                                                        scoring=\"neg_mean_absolute_error\"\n",
    "                                                    )\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3), sharey=True, sharex=True)\n",
    "_plot_learning_curve(estimator, train_sizes, train_scores, valid_scores, plt_text=f'X={[\"Distance\"]}, Y={target}', ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225b2f7-9043-4f20-b1c5-3bcfdd3b97c8",
   "metadata": {},
   "source": [
    "### 4.1 Making a decision:\n",
    "* The LinearRegression model with a single `X` feature will `underfit` almost all non-trivial datasets.\n",
    "* The `R2 Score at 0.03` shows the model can explain 3% of the dataset's price.\n",
    "* The `MAE` metric shows `half-a-million-dollars` error on average for predictions.\n",
    "* The `error analysis plot` above shows wide errors on the 5-15 KM distance properties.\n",
    "\n",
    "All of this information suggests the model is `underfitting` the dataset. So we will `complexify` the modelling process in the next step.\n",
    "\n",
    "Also see the table in the slides for decision actions for `underfit` and `overfit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8ed71-cad1-4772-aa8e-00d18442ca69",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48149ee1-0d77-4c40-8f3a-0f7a07c83641",
   "metadata": {},
   "source": [
    "## 5. `Complexify` Model / Features:\n",
    "\n",
    "\n",
    "Our options for `underfitting` are:\n",
    "1. Increase number of features\n",
    "2. Increase feature representation (embeddings / feature engineering)\n",
    "3. Increase model complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849b89f-6765-4184-8f26-f8142d9a9f9c",
   "metadata": {},
   "source": [
    "## 6. Increase number of features\n",
    "### 6.1 Multiple Feature Number Prediction: (Multivariate Linear Regression)\n",
    "\n",
    "This week we will use more than a single feature `[x1,x2,x3,...]->Price` (`X->Y`) to get a prediction.\n",
    "\n",
    "Let's just try that and collect the errors summary as an initial comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c911cb-e2da-4339-a93b-b401a2234b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_estimator_1( estimator, X_train, X_test, y_train, y_test, features ):\n",
    "    estimator.fit(X_train, y_train)\n",
    "    input_to_predict =  X_train[0].reshape(1, -1)\n",
    "    y_pred = estimator.predict( input_to_predict )\n",
    "    y_true = y_train[0]\n",
    "    error = y_true - y_pred\n",
    "    print(f'For this data-point {dict(zip(features,input_to_predict[0]))} in the Price prediction (estimate) had an AUD $ {error[0][0]:,.2f} (error)')\n",
    "    # Take out the integer value (from the numpy arrays. In this case, the value is wrapped by two arrays, hence [0][0])\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(f\"Test: mean_absolute_error: {mean_absolute_error(y_test, y_pred):,.2f}\")\n",
    "    print(f\"Test: r2_score: {r2_score(y_test, y_pred):,.2f}\")\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba23d5-0f3d-4e5c-ba96-c5b718efd8dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X, y = get_some_data( df, features, target )\n",
    "estimator = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1) # Split into 85% training and 15% testing data\n",
    "\n",
    "estimator = _evaluate_estimator_1( estimator, X_train, X_test, y_train, y_test, features )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed440945-c2bb-4a8e-b935-ab43e9944602",
   "metadata": {},
   "source": [
    "* Adding the extra features `improved the MAE and R2 summary error metrics` and it reduced the specific error for our 1 data-point trial at `Distance=11.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee33775-8e2d-40ef-aba7-c0717890ba33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"----------------\\nHere's the estimator function found by Linear Regression:\")\n",
    "eq = _extract_model_parameters(estimator, features)\n",
    "print(eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3228677-28d4-4104-885a-2c2d3653c88c",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "#### Add Scaler into Pipeline:\n",
    "- *(Pipeline evaluation functions)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e51cbd-5436-424d-8d6d-db9d307a8733",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def _fit_cv_eval_pipeline(pipeline, X_train, y_train,\n",
    "                        preferred_metric='neg_mean_squared_error', kfolds=5, random_state=0 ):\n",
    "    \n",
    "    kf = KFold(n_splits=kfolds, shuffle=True, random_state=random_state)\n",
    "    cv_scores = cross_validate( pipeline,\n",
    "                                X_train, y_train,\n",
    "                                cv=kf,\n",
    "                                scoring=preferred_metric,\n",
    "                                error_score='raise',\n",
    "                                return_estimator=True)\n",
    "    min_index = np.argmin(cv_scores['test_score'])\n",
    "    best_cv_pipeline = cv_scores['estimator'][min_index]\n",
    "    #y_pred = best_cv_pipeline.predict(X_test) # Get best from K-folds set.\n",
    "    pipeline.fit(X_train, y_train) # Refit the model on the entire dataset.\n",
    "    return cv_scores, best_cv_pipeline, pipeline\n",
    "\n",
    "def _evaluate_pipeline_2( pipeline, X_train, X_test, y_train, y_test, features ):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    input_to_predict = X_train[0].reshape(1, -1)\n",
    "    input_to_predict_transformed = pipeline.named_steps['scaler'].transform(input_to_predict)\n",
    "    y_pred = pipeline.predict( input_to_predict )\n",
    "    y_true = y_train[0]\n",
    "    error = y_true - y_pred\n",
    "    print(f'For this data-point {dict(zip(features,input_to_predict[0]))} in the Price prediction (estimate) had an AUD $ {error[0][0]:,.2f} (error)')\n",
    "    print(f' - Transformed inputs: {dict(zip(features,input_to_predict_transformed[0]))}')\n",
    "    # Take out the integer value (from the numpy arrays. In this case, the value is wrapped by two arrays, hence [0][0])\n",
    "    X_test_transformed = pipeline.named_steps['scaler'].transform(X_test)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(f\"mean_absolute_error: {mean_absolute_error(y_test, y_pred):,.2f}\")\n",
    "    print(f\"r2_score: {r2_score(y_test, y_pred):,.2f}\")\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d99f5-3717-4465-b07a-1b2100f1d704",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = get_some_data( df, features, target )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1) # Split into 85% training and 15% testing data\n",
    "\n",
    "estimator = LinearRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # StandardScaler\n",
    "    ('regressor', estimator)       # Regressor estimator\n",
    "])\n",
    "\n",
    "_, _, pipeline = _fit_cv_eval_pipeline(pipeline, X_train, y_train)\n",
    "_ = _evaluate_estimator_1( pipeline, X_train, X_test, y_train, y_test, features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512fe587-942a-4a9d-b9cc-76bd2bc89995",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pipeline = _evaluate_pipeline_2( pipeline, X_train, X_test, y_train, y_test, features )\n",
    "pip_estimator = pipeline.named_steps['regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73e77a-172a-484d-b02d-c03711ae6861",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"----------------\\nHere's the estimator function found by Linear Regression:\")\n",
    "eq = _extract_model_parameters(pip_estimator, features)\n",
    "print(eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2709b4c-6e2d-4965-af36-4fd980a4242a",
   "metadata": {},
   "source": [
    "### 6.2 Residual Error Plot of Price (Y) Error Distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a9ad2-2ac5-4555-be4c-f0cec3684313",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def _plot_regression_distance_errors2( X_set, y_set, pipeline):\n",
    "\n",
    "    y_pred = pipeline.predict( X_set )\n",
    "    residuals = y_set - y_pred\n",
    "    \n",
    "    X_list = np.array([i for i in range(len(X_set))]).reshape(len(X_set), 1)\n",
    "    zeroes = np.array([0 for i in range(len(X_set))]).reshape(len(X_set), 1)\n",
    "    # Plot data and individual distance errors\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in X_list:\n",
    "        plt.plot([X_list[i][0], X_list[i][0]], [zeroes[i][0], residuals[i][0]], color=\"gray\", lw=0.75, linestyle=\"dashed\")\n",
    "    plt.scatter(X_list, residuals, color=\"blue\", label=\"Error values\", s=10)\n",
    "    plt.plot(X_list, zeroes, color=\"red\", label=\"Zero Error line\")\n",
    "    \n",
    "    # Plot individual errors as vertical lines\n",
    "    plt.xlabel(\"Input # (X)\")\n",
    "    plt.ylabel(\"Residual Error (of Target (y))\")\n",
    "    plt.title(f\"Regression Model with Residual Errors (n={len(X_set):,})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    from matplotlib.lines import Line2D\n",
    "    error_line = Line2D([], [], color='gray', linestyle='--', lw=0.5, label='Error distance per point')\n",
    "    plt.legend(handles=[*plt.gca().get_legend_handles_labels()[0], error_line])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _plot_regression_distance_errors3( X_set, y_set, pipeline, features, feature_idx=0):\n",
    "\n",
    "    y_pred = pipeline.predict( X_set )\n",
    "    residuals = y_set - y_pred\n",
    "\n",
    "    # Sort by the selected feature\n",
    "    feature_name = features[feature_idx]\n",
    "    sorted_indices = np.argsort(X_set[:, feature_idx])  # Sort based on feature index\n",
    "    X_sorted = X_set[sorted_indices]  \n",
    "    y_sorted = y_set[sorted_indices]\n",
    "    residuals_sorted = residuals[sorted_indices]\n",
    "    \n",
    "    X_list = X_sorted[:, feature_idx].reshape(len(X_set), 1)\n",
    "    zeroes = np.zeros_like(X_list).reshape(len(X_set), 1)\n",
    "    # Plot data and individual distance errors\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i in range(len(X_list)):\n",
    "        plt.plot([X_list[i][0], X_list[i][0]], [zeroes[i][0], residuals_sorted[i][0]], color=\"gray\", lw=0.75, linestyle=\"dashed\")\n",
    "    plt.scatter(X_list, residuals_sorted, color=\"blue\", label=\"Error values\", s=10)\n",
    "    plt.plot(X_list, zeroes, color=\"red\", label=\"Zero Error line\")\n",
    "    \n",
    "    # Plot individual errors as vertical lines\n",
    "    plt.xlabel(f\"{feature_name} Value (X)\")\n",
    "    plt.ylabel(\"Residual Error (of Target (y))\")\n",
    "    plt.title(f\"Regression Model with Residual Errors for {feature_name} (n={len(X_set):,})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    from matplotlib.lines import Line2D\n",
    "    error_line = Line2D([], [], color='gray', linestyle='--', lw=0.5, label='Error distance per point')\n",
    "    plt.legend(handles=[*plt.gca().get_legend_handles_labels()[0], error_line])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca992c-2edc-4dbd-92f0-35ae17d165c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,_ in enumerate(features):\n",
    "    _plot_regression_distance_errors3( X_test, y_test, pipeline, features, feature_idx=i  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c5513-d15c-4b72-ba55-478a2ef7435a",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "## 7. Further Increase Number of Features:\n",
    "\n",
    "We can add even more features to check its impact on improving the model.\n",
    "\n",
    "* Adding more features will probably help.\n",
    "* Let's also check the `feature importance` of each `X` feature, to help us understand which are best at predicting the Price `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6717e-b004-4724-b888-06b38770065e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X, y = get_some_data( df, features+['YearBuilt','Bedroom2'], target )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1) # Split into 85% training and 15% testing data\n",
    "\n",
    "estimator = LinearRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # StandardScaler\n",
    "    ('regressor', estimator)       # Regressor estimator\n",
    "])\n",
    "\n",
    "_, _, pipeline = _fit_cv_eval_pipeline(pipeline, X_train, y_train)\n",
    "\n",
    "_ = _evaluate_estimator_1( pipeline, X_train, X_test, y_train, y_test, features+['YearBuilt','Bedroom2'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b7fd2-9824-4bf6-8ac1-f5a0614b32d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pipeline = _evaluate_pipeline_2( pipeline, X_train, X_test, y_train, y_test, features+['YearBuilt','Bedroom2'] )\n",
    "pip_estimator = pipeline.named_steps['regressor']\n",
    "print(\"----------------\\nHere's the estimator function found by Linear Regression:\")\n",
    "eq = _extract_model_parameters(pip_estimator, features)\n",
    "print(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb88b3a-63b4-4444-92ca-819aaadca2b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,_ in enumerate(features+['YearBuilt','Bedroom2']):\n",
    "    _plot_regression_distance_errors3( X_test, y_test, pipeline, features+['YearBuilt','Bedroom2'], feature_idx=i  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc464e-4bf9-488b-993e-b9996da51f17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def display_feature_importance( pipeline, feature_names ):\n",
    "    # Extract absolute coefficients as feature importance\n",
    "    coefficients = np.abs(pipeline.named_steps['regressor'].coef_[0])\n",
    "    \n",
    "    # Create a DataFrame for reporting feature importance\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance (abs coef)': coefficients\n",
    "    }).sort_values(by=\"Importance (abs coef)\", ascending=False)\n",
    "    \n",
    "    display(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5aaec5-dd2c-4716-b916-a2db316cd5b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "X, y = get_some_data( df, features+['YearBuilt','Bedroom2'], target )\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_prescaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113fb02-9921-4061-a361-db9146e2441f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_prescaled, y, test_size=0.15, random_state=1) # Split into 85% training and 15% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c4bfb-3a10-4ab1-b804-1f7af2402e0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "estimator = LinearRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # StandardScaler\n",
    "    ('regressor', estimator)       # Regressor estimator\n",
    "])\n",
    "\n",
    "_, _, pipeline = _fit_cv_eval_pipeline(pipeline, X_train, y_train)\n",
    "\n",
    "display_feature_importance( pipeline, feature_names=features+['YearBuilt','Bedroom2'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc3a99-25b4-4121-ba24-ca683428444f",
   "metadata": {},
   "source": [
    "* The ranked features are shown above. Top is most important for predicting the Price `Y` target.\n",
    "* The large coefficients are not so easily `interpretable` (as they are now in Standard-Deviation Unit scale). They are still large, because the Price predication value is large.\n",
    "* Adding `YearBuilt` was valuable. It is ranked number 2.\n",
    "* Adding `Bedroom2` was less valuable (less important) according to the variance in Price explained by the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49d8ba2-052a-489b-8264-93e93dc5395f",
   "metadata": {},
   "source": [
    "### 7.2 Extras - Feature Importance Plots: SHAP Summary Plot:\n",
    "\n",
    "We can also plot the feature importance visually, according to the `RobustScaled` and `StandardScaled` model. We can use the `Shap` library for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143b3e8-78fe-41fc-9ac6-68976d825ea2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def _display_shap_plots(pipeline, X_train, feature_names):    \n",
    "    # Initialize SHAP explainer\n",
    "    explainer = shap.Explainer(pipeline.named_steps['regressor'], X_train)\n",
    "    # Compute SHAP values\n",
    "    shap_values = explainer(X_train)\n",
    "    # Summary plot (shows feature importance)\n",
    "    shap.summary_plot(shap_values, X_train, feature_names, show=False)\n",
    "    plt.gcf().set_size_inches(7,3)\n",
    "    plt.title('Summary Plot', fontsize=9)\n",
    "    plt.gca().tick_params(axis='both', labelsize=9)\n",
    "    plt.gca().tick_params(axis='both', labelsize=9)\n",
    "    plt.xlabel(plt.gca().get_xlabel(),fontsize=9)\n",
    "    plt.ylabel(plt.gca().get_ylabel(),fontsize=9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185858ff-c825-4718-b8df-e7bd46b31a87",
   "metadata": {},
   "source": [
    "The Summary Plot of Features is produced below. It is a scatter plot showing how each feature affects predictions, according to its `shap value`.\n",
    "\n",
    "* Intuitively, these `shap-value` `dots` show the average contribution of a specific feature to a model's prediction.\n",
    "    * i.e.\n",
    "        * A `positive shap-value` shows the feature `increases Price`.\n",
    "        * A `negative shap-value` shows the feature `decreases Price`.\n",
    "    * Red = higher feature values, Blue = lower feature values.\n",
    "    * Features are ranked by importance (top = most important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420b32a-8ec7-417f-8ac3-b0730b0ed3b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# _display_shap_plots(pipeline, X_train, feature_names=features+['YearBuilt','Bedroom2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23006b40-1ea7-42ec-94db-c7c4fb340697",
   "metadata": {},
   "source": [
    "* Mostly High (red) values of `YearBuilt` decrease the Price.\n",
    "* Mostly High (red) values of `BuildingArea` increase the Price.\n",
    "* The most valuable aspect is the scale of effect, so the top-ranked features have the most positive impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24b706-3862-40c2-9781-b85f370c1d11",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "## 8. Increase model parameters and feature representation (embeddings / feature engineering): - Polynomial Linear Regression:\n",
    "\n",
    "We can further improve model performance by modifying the feature representations. This is partly feature engineering and is a data preprocessing step.\n",
    "\n",
    "* We will use polynomial feature expansion.\n",
    "* 👉 However, this approach has a `specific drawback` - It will `overfit` the training data. Because of this problem, `all new algorithms have much cleverer solutions to solve this problem than Polynomials`.\n",
    "* 👉 This underlying drawback is `the key reason why we use more sophisticated algorithms for most predictive modelling tasks`. (You will see those in later weeks and later in your studies).\n",
    "\n",
    "👉 Let's take a look (and find the breaking point!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e1f54-7d4c-474c-b4ed-3f9d9a874615",
   "metadata": {},
   "source": [
    "### 8.1 - 1 Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91658c93-7c56-458f-b852-a1a60f407e84",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = get_some_data( df, features+['YearBuilt','Bedroom2'], target )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1) # Split into 85% training and 15% testing data\n",
    "estimator = LinearRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=1, include_bias=False)),\n",
    "    ('scaler', StandardScaler()),  # StandardScaler\n",
    "    ('regressor', estimator)       # Regressor estimator\n",
    "])\n",
    "\n",
    "_, _, pipeline = _fit_cv_eval_pipeline(pipeline, X_train, y_train)\n",
    "_ = _evaluate_estimator_1( pipeline, X_train, X_test, y_train, y_test, features+['YearBuilt','Bedroom2'] )\n",
    "\n",
    "y_pred = pipeline.predict(X_train)\n",
    "print(f\"Train: mean_absolute_error: {mean_absolute_error(y_train, y_pred):,.2f}\")\n",
    "print(f\"Train: r2_score: {r2_score(y_train, y_pred):,.2f}\")\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"Has \", len(pipeline.named_steps['regressor'].coef_[0])+1, 'parameters')\n",
    "print(\"Has \", X.shape[1], 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf62ba-7cd2-4a81-bdf4-3dad8138d293",
   "metadata": {},
   "source": [
    "### 8.1 - >1 Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa2fba-c7c6-4838-8617-e98873474e12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _eval_poly_degree(deg=2, features=[], target=[]):\n",
    "    X, y = get_some_data( df, features, target )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1) # Split into 85% training and 15% testing data\n",
    "    estimator = LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=deg, include_bias=False)),\n",
    "        ('scaler', StandardScaler()),  # StandardScaler\n",
    "        ('regressor', estimator)       # Regressor estimator\n",
    "    ])\n",
    "    \n",
    "    _, _, pipeline = _fit_cv_eval_pipeline(pipeline, X_train, y_train)\n",
    "    _ = _evaluate_estimator_1( pipeline, X_train, X_test, y_train, y_test, features+['YearBuilt','Bedroom2'] )\n",
    "    \n",
    "    y_pred = pipeline.predict(X_train)\n",
    "    print(f\"Train: mean_absolute_error: {mean_absolute_error(y_train, y_pred):,.2f}\")\n",
    "    print(f\"Train: r2_score: {r2_score(y_train, y_pred):,.2f}\")\n",
    "    print(\"----------------\")\n",
    "    print(\"Has \", len(pipeline.named_steps['regressor'].coef_[0])+1, 'parameters')\n",
    "    print(\"Has \", X.shape[1], 'features')\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfce32-bc80-4f6b-ab61-54ddb94dd69e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    print('-------\\n Polynomial degree:',i,':')\n",
    "    pip = _eval_poly_degree(i, features+['YearBuilt','Bedroom2'], target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9cfd86-e170-4f49-8239-84590a382d48",
   "metadata": {},
   "source": [
    "### 8.1 - >1 Degree Polynomial & Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbda390-2528-44b0-a8a5-4489b53a213f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _plot_learning_curve_poly1( pipeline, X_train, y_train, plt_text='' ):\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(\n",
    "        pipeline, \n",
    "        X_train, y_train, \n",
    "        train_sizes=np.linspace(0.5, 1.0, 50), \n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_absolute_error\"\n",
    "    )\n",
    "    _plot_learning_curve(pipeline, train_sizes, train_scores, valid_scores, metric='MAE', plt_text=plt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6c3fa-bf6c-40a0-985b-cf797033cc81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    print('-------\\n Polynomial degree:',i,':')\n",
    "    pip = _eval_poly_degree(i, features+['YearBuilt','Bedroom2'], target)\n",
    "    _plot_learning_curve_poly1( pip, X_train, y_train, plt_text=f\"X={features+['YearBuilt','Bedroom2']}, Y={target}\" )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2212d-4883-4baa-9666-9b37046e227d",
   "metadata": {},
   "source": [
    "* `Negative R2 score` means the model is performing `worse than predicting the mean Price`.\n",
    "* It also gets slower and slower as we increase the polynomial degree, and its number of parameters.\n",
    "* By increasing the parameters the training data is fitting better. So it's partly helpful. But we need a better solution.\n",
    "* This is why we use smarter algorithms to `prevent overfitting` while improving `generalized fit` (on train and test) by `regularizing` the parameters. (More on this in later topics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b580c46-dee5-47cc-b552-9a0bcae10a70",
   "metadata": {},
   "source": [
    "## 9. Concluding:\n",
    "\n",
    "Improving `feature representations` using Polynomial equations increased the number of model parameters and the estimator function's expressiveness to the data, which improved the training set performance, but weakened the test set.\n",
    "\n",
    "It `overfitted our training data`, which can see via the learning curves.\n",
    "\n",
    "Therefore we need to choose smart algorithms when we `complexify` (which you will do shortly).\n",
    "\n",
    "In `Lab 07 Assignment` you will use a smarter (more sophisticated) algorithm to model and predict the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df3d93-e731-4060-998b-9c4bc39d8f3e",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">That's it! Congratulations! <br> \n",
    "    Let's now work on your lab assigment.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c08609-2a29-431d-9583-82bd1a685a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 10. Extras - When to Scale Features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241dea19-00bc-4aa2-8c16-8af174cf1f2a",
   "metadata": {},
   "source": [
    "❌  If `interpretation in original units` is important → No scaling. \n",
    "* **`Feature Intepretation is useful to explain the behaviour of each feature, according to the model and its error.`**\n",
    "    * In this case, coefficients show real-world impact per unit increase.\n",
    "    * If we did not rescale the features, equal unit changes to `Landsize` (meters-sq) and `Bathrooms` (qty) will have unequal unit-effects (magnitudinal effects) on the prediction values.\n",
    "    * This is fine if we want to `explain`/ `interpret` the coefficients of each feature. I.e. - `how much does an extra bathroom cost, according to the model?`\n",
    "    * We can see this clearly in the coefficients.\n",
    "    * For this week's new models, `intercept` is also very different; starting value of `200k AUD-$` instead of `1,000,000 AUD-$` (as last week).\n",
    "\n",
    "✅ If comparing `feature importance` is the goal → Use StandardScaler. \n",
    "* **`Feature Importance is useful to select the best features in order to improve model performance.`**\n",
    "    * *We know how to do that (`Hint: Lab 05`).*\n",
    "    * In this case, coefficients are in `standard deviation units`. A value of 1 is equal to 1 standard deviation from mean. That unit value (1) is equal across all features, making them comparable.\n",
    "    * `StandardScaler` transforms each numeric feature as `mean = 0, variance = 1`.\n",
    "    * If `# Bedrooms` standard deviation is 1 (e.g. range 1-3, mean is 2), and `Landsize` std is 50 (range 20-100, mean is 50), their 1-std value change becomes equivalent.\n",
    "    * We can also use the sklearn's `Pipeline` to \"magically\" manage this for us.\n",
    "* How that works:\n",
    "    * First, we `.fit_transform(..)` on the `X_Train` dataset.\n",
    "    * Then we apply that fitted transform function (which only knows about our `training data`) using `.transform(...)`, to the `X_test` (our testing dataset).\n",
    "    * If we want to predict a `new input` later (unseen, i.e. you decide to type in some values), we also need to apply  `.transform(...)` again to that data, to keep the relative numbers equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa64a07-9653-4c29-8e48-1e09aa9efcf9",
   "metadata": {},
   "source": [
    "### 10.1 Example of manually scaling inputs for predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad00389-1310-4594-8c91-ee1f4ab91d23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = get_some_data( df, ['Distance'], target )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0) # Split into 85% training and 15% testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ecf2d7-c8a2-4249-871f-183953901c1e",
   "metadata": {},
   "source": [
    "* Manually transform entire test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d3751-ece3-455e-b5c6-31a613e31e19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "estimator = _evaluate_estimator_1( LinearRegression(), X_train_scaled, X_test_scaled, y_train, y_test, features )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb5d4c-ffe2-425d-96bc-eea8cf4614f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "* Notice, the errors will be the same; but the input values changed.\n",
    "* The `Y` Value is still in the usual range of `AUD-$` dollars.\n",
    "\n",
    "(NB: **Very rarely** do we transform the `Y` value, because it is more useful in its original scale.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc6497-b95f-4b03-9ff8-bd96de4a9813",
   "metadata": {},
   "source": [
    "* Manually transform 1 input from train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a536d-3510-4202-8d77-3b152f39675d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_new_data = scaler_X.transform( X_train[0].reshape(1, -1) ) # i.e. transform some new input data to predict.\n",
    "print(X_new_data)\n",
    "estimator.predict(X_new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e374dda-f354-49b5-8b8f-a88383c006e9",
   "metadata": {},
   "source": [
    "* Manually transform 1 new unseen input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9bfef-0996-47f9-86fa-4d705e28c492",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_new_data = scaler_X.transform([[ 11.2 ]]) # i.e. transform some new input data to predict.\n",
    "print(X_new_data)\n",
    "estimator.predict(X_new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
